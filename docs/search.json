[
  {
    "objectID": "course-materials/lectures/Brief R history.html",
    "href": "course-materials/lectures/Brief R history.html",
    "title": "History of R",
    "section": "",
    "text": "A simple history of R.\nSee this site for a longer history with fewer pictures.\n\n\nBefore R there was S\n“S is a language that was developed by John Chambers and others at the old Bell Telephone Laboratories”\n\n\n\nJohn Chambers at Stanford\n\n\n\n\nS got bought and sold\nHere’s a book on S\n\n\n\n\n\n\n\n1996-2000 R is release for free\nRoss Ihaka and Robert Gentleman of the university of Auckland Developed it.\n\n\nRoss Ihaka\n\nPhoto by Kristina D.C. Hoeppner from Wellington, New Zealand - Ross Ihaka, CC BY-SA 2.0, https://commons.wikimedia.org/w/index.php?curid=37005667\n\n\nRobert Gentleman\n\n\n\nRobert Gentleman\n\n\nPhoto by Aneesulrehman - Own work, CC BY-SA 4.0, https://commons.wikimedia.org/w/index.php?curid=89993843\n\n\nWhy is it called R?\n\n\nCRAN\nComprehensive R Archive Network\nThey manage all R updates and R packages. There are currently 19897 packages.\nThey put on the UseR! conference\nThere’s an R magazine\nThis is the CRAN team\n\n\nWho made the tidyverse\n\n\n\n\n\nPhoto by By Hadley Wickham - Private correspondence, CC BY-SA 4.0, https://commons.wikimedia.org/w/index.php?curid=46810731\n\n\nWho makes RStudio?\n\n\nStarted in 2009 as RStudio\nThe tidyverse comes out in 2016\nRenamed Posit last year.\nOffers Python Support\n\n\n\n\nThings lots of people know about R\nDefault Colors palmerpenguins mtcars"
  },
  {
    "objectID": "index.html#colors",
    "href": "index.html#colors",
    "title": "SDS 192: Intro to Data Science",
    "section": "Colors",
    "text": "Colors\n\nlive_demo\nColor Brewer site\nProf. Cao’s Lecture on Frequency Plots and Facets\nIn class exercise"
  },
  {
    "objectID": "index.html#the-c-function-typing-math-and-tibbles",
    "href": "index.html#the-c-function-typing-math-and-tibbles",
    "title": "SDS 192: Intro to Data Science",
    "section": "The c() function, typing math, and tibbles",
    "text": "The c() function, typing math, and tibbles"
  },
  {
    "objectID": "index.html#history-of-r",
    "href": "index.html#history-of-r",
    "title": "SDS 192: Intro to Data Science",
    "section": "History of R",
    "text": "History of R"
  },
  {
    "objectID": "index.html#other-things",
    "href": "index.html#other-things",
    "title": "SDS 192: Intro to Data Science",
    "section": "Other things",
    "text": "Other things\n\n\n\n\n\n\nTo activate colors\n\n\n\n\n\nSome students are not getting “red” to be red. Try this: Tools menu &gt; global options &gt; code &gt; display &gt; “enable preview of named and hex colors\nIf that doesn’t work, maybe its a bug?\n\n\n\n\nthe c() function\ntyping math\nand tibbles\nggplot cheatsheet\nThe visual editor\nShort History of R"
  },
  {
    "objectID": "Resources.html#moderndive",
    "href": "Resources.html#moderndive",
    "title": "Resources",
    "section": "ModernDive",
    "text": "ModernDive"
  },
  {
    "objectID": "Resources.html#data-science-in-a-box",
    "href": "Resources.html#data-science-in-a-box",
    "title": "Resources",
    "section": "Data Science in a box",
    "text": "Data Science in a box"
  },
  {
    "objectID": "Resources.html#data-visualization-ggplot2",
    "href": "Resources.html#data-visualization-ggplot2",
    "title": "Resources",
    "section": "Data Visualization: ggplot2",
    "text": "Data Visualization: ggplot2"
  },
  {
    "objectID": "Resources.html#data-transformation-dplyr",
    "href": "Resources.html#data-transformation-dplyr",
    "title": "Resources",
    "section": "Data transformation: dplyr",
    "text": "Data transformation: dplyr"
  },
  {
    "objectID": "Resources.html#data-import-tidyr",
    "href": "Resources.html#data-import-tidyr",
    "title": "Resources",
    "section": "Data Import: tidyr",
    "text": "Data Import: tidyr"
  },
  {
    "objectID": "Resources.html#rmarkdown-cheat-sheet",
    "href": "Resources.html#rmarkdown-cheat-sheet",
    "title": "Resources",
    "section": "RMarkdown Cheat sheet",
    "text": "RMarkdown Cheat sheet"
  },
  {
    "objectID": "Resources.html#style-guide",
    "href": "Resources.html#style-guide",
    "title": "Resources",
    "section": "Style Guide",
    "text": "Style Guide\nThe Tidyverse Style Guide"
  },
  {
    "objectID": "index.html#descriptive-stats-and-boxplots",
    "href": "index.html#descriptive-stats-and-boxplots",
    "title": "SDS 192: Intro to Data Science",
    "section": "Descriptive stats and boxplots",
    "text": "Descriptive stats and boxplots\n\nMDSR Chapter 3.5 problem 3 and 7\nHints: - you might need to install mosaicdata\n\nlook for the correct graph for 7c on the cheat sheet"
  },
  {
    "objectID": "index.html#lecture-descriptive-stats-and-boxplots",
    "href": "index.html#lecture-descriptive-stats-and-boxplots",
    "title": "SDS 192: Intro to Data Science",
    "section": "Lecture: Descriptive stats and boxplots",
    "text": "Lecture: Descriptive stats and boxplots\n\nClasswork: MDSR Chapter 3.5 problem 3 and 7\nHints:\n\nyou might need to install mosaicdata\nlook for the correct graph for 7c on the cheat sheet"
  },
  {
    "objectID": "course-materials/lectures/Making-data-frames.html",
    "href": "course-materials/lectures/Making-data-frames.html",
    "title": "Making Data Frames",
    "section": "",
    "text": "Weather\n\n\n\nVectors\nMake three vectors with the day of the month, the weather and temperature.\n\nday &lt;- c(9, 10,11,12,13,14,15)\nweather &lt;- c()\ntemperature &lt;- c()\n\n\n\nUniqueness\n\nunique()\nunique(weather)\n\n\n\nMake a dataframe\n\nWeek_in_sept &lt;- data.frame(day,weather,temperature)\n\n\n\nLet’s take a look\n\nWeek_in_sept\n\n\nglimpse(Week_in_sept)\nhead(): returns first 6 rows\ntails(): returns last 6 rows\nnames(): returns the coloumn names\nnrow(): returns the number of rows\nncol(): returns the number of columns\n\n\n\nRenaming columns\nSave the new column names as a vector and use the names() function.\nWeekdays &lt;- c(“Sunday”,“Monday”,“Tuesday”,“Wednesday”….)\nnames(Week_in_sept) &lt;- Weekdays\n\n\nColumns\nWe can use the $ to access columns as vectors Week_in_sept$Monday\nLet’s do table() on Monday\n\n\nA dataset\n\nColumns are variables\nRows are observations\nIndividual entries are called values\nThe data we will deal with in this course is rectangular.\n\n\nMetadata\nThis is the data about our data.\nSometimes a data dictionary comes with our data.\nWhen data comes in a package we can use the ? operator.\nMetadata deals with provenance.\nDescriptive Data deals with the contents of the data.\nLet’s consider ChickWeight and its metadata\n\n\nCredits\nWeather map- https://weather.com/forecast/news/2014-10-31-national-forecast-20141009\nData Frame Image- Grolemund, Garrett, and Hadley Wickham. n.d. R for Data Science. Accessed March 31, 2019. https://r4ds.had.co.nz/."
  },
  {
    "objectID": "course-materials/lectures/ethics.html#algorithms-reflect-the-bais-of-their-creator",
    "href": "course-materials/lectures/ethics.html#algorithms-reflect-the-bais-of-their-creator",
    "title": "Data Ethics",
    "section": "Algorithms Reflect the bais of their creator",
    "text": "Algorithms Reflect the bais of their creator\n\nA piece of data itself has no positive or negative moral value, but the way we manipulate it does. It’s hard to imagine a more contentious project than programing ethics into our algorithms; to do otherwise, however, and allow algorithms to monitor themselves, is to invite the quicksand of moral equivalence."
  },
  {
    "objectID": "course-materials/lectures/ethics.html#books",
    "href": "course-materials/lectures/ethics.html#books",
    "title": "Data Ethics",
    "section": "Books",
    "text": "Books"
  },
  {
    "objectID": "course-materials/lectures/ethics.html#last-slide",
    "href": "course-materials/lectures/ethics.html#last-slide",
    "title": "Data Ethics",
    "section": "Last Slide",
    "text": "Last Slide\n\nChistopher Wylie https://www.nytimes.com/2018/03/17/us/politics/cambridge-analytica-trump-campaign.html\nMichal Kosinski and Yilun Wang https://www.nytimes.com/2017/10/09/science/stanford-sexual-orientation-study.html\nNew Yorker https://www.newyorker.com/news/daily-comment/the-ai-gaydar-study-and-the-real-dangers-of-big-data"
  },
  {
    "objectID": "schwab.html",
    "href": "schwab.html",
    "title": "Nic Schwab",
    "section": "",
    "text": "Nicholas Schwab is a visiting lecture in Statistical and Data Sciences. He is a tenured professor at Holyoke Community College. When not teaching data science, he enjoys rock climbing, running, and reading childrens’ books to his kids."
  },
  {
    "objectID": "schwab.html#student-hours",
    "href": "schwab.html#student-hours",
    "title": "Nic Schwab",
    "section": "Student Hours",
    "text": "Student Hours\nDrop into the office: Monday: 1:35-2:35 pm, Friday: 12:45 pm -1:45pm or by appointment. in McConnell 213\nPlease let me know if the above times do not work for your schedule and we can coordinate another time."
  },
  {
    "objectID": "schwab.html#education",
    "href": "schwab.html#education",
    "title": "Nic Schwab",
    "section": "Education",
    "text": "Education\n\nMS in Data Science (~2026)\nUniversity of Texas at Austin\nAustin, Texas\nMA in Mathematics (2009)\nAppalchain State University\nBoone, NC\nBA in Mathematics (2007)\nUC Santa Cruz\nSanta Cruz, CA"
  },
  {
    "objectID": "schwab.html#experience",
    "href": "schwab.html#experience",
    "title": "Nic Schwab",
    "section": "Experience",
    "text": "Experience\n\nProfessor of Mathematics\nHolyoke Community College\nHolyoke, MA 2014–2023"
  },
  {
    "objectID": "course-materials/lectures/github_practice.html",
    "href": "course-materials/lectures/github_practice.html",
    "title": "Real Github Practice",
    "section": "",
    "text": "Pushing to Main\nWe’ve seen how messy this can get.\nYou can push to main when you are working alone (and always on one computer).\nDirected Acyclic Graph (DAG) picture.\n\nA node is a commit\nEdges point to the parent\n\n\n\nBranches\nWhen working with other people create branches.\nBranches allow you to work without mucking up other’s work.\nIf two people edit the same line of code at the same time and pushed to main?\nGithub doesn’t know which to take and you get a tricky merge conflict.\n\n\nStep 1: Create a fresh project 1 .rproj file.\nDon’t delete your .qmd if you’ve been working on it.\nWe’ll get to it later.\n\n\nStep 2: Create a new branch.\n\n\nGive it a good name. No spaces.\nYour partner should give a different branch name.\n\n\n\nStep 3: Change a small thing.\nWe will change the authors’ names in our project.\nWork out with your partner who is author 1 and 2 (and 3).\n\n\nStep 4: Save and commit.\nYour partners are doing the same thing.\nNote: When you commit your branch gets a new node.\nDirected Acyclic Graph (DAG) picture.\n\n\nStep 5: Pull then Push your branch to github.\nIn general it is a good idea to pull first to get any new changes before you push.\n\n\n\nStep 6: Go to github.\n\n\n\nYou should see something like this. Except with your branch name instead of practice.\n\n\n\n\nStep 7: Create a pull request for your branch\nYou are pulling your files to the main branch.\nBoth you and your partner will do this.\nHopefully you’ll be able to do an auto merge.\n\nGive your pull request a good message too.\n\n\nStep 8: Merge Branches\n\nDo this one at a time.\nYou can delete the old branch.\n\nYou’ll make a new one.\n\n\n\n\nStep 9: Switch back to main and pull\n\nCheck your files are updated with both names.\n\n\nMerge Conflict practice\n\n\nNew Branch - Good Name\nYou and your partner should change the title of your project.\n\nChoose different titles\n\nCommit and push to github.\nGo to github to fix the merge conflict.\nSometimes github will tell you go to the command line\n\nOpen the Terminal and type what it says.\n\n\n\n\n\nSometimes a file changes.\nhead &gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;\nmake changes in your file and delete the excess.\n&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;\n\n\nExplore\n\nhistory\nbranches\npull requests\n\n\n\nProject work\nMake a simple graph and push to github.\nAlways work in separate branches not on main."
  },
  {
    "objectID": "course-materials/lectures/ethics.html#credits",
    "href": "course-materials/lectures/ethics.html#credits",
    "title": "Data Ethics",
    "section": "Credits",
    "text": "Credits\n\nSome Content was taken from Ben Baumer’s Lecture on Ethics\nChistopher Wylie https://www.nytimes.com/2018/03/17/us/politics/cambridge-analytica-trump-campaign.html\nMichal Kosinski and Yilun Wang https://www.nytimes.com/2017/10/09/science/stanford-sexual-orientation-study.html\nNew Yorker https://www.newyorker.com/news/daily-comment/the-ai-gaydar-study-and-the-real-dangers-of-big-data"
  },
  {
    "objectID": "course-materials/lectures/Wrangling_1_SQF.html",
    "href": "course-materials/lectures/Wrangling_1_SQF.html",
    "title": "Presentation",
    "section": "",
    "text": "Stop, Question, Frisk\n\nNew York City Police Practice\nMany articles about the targeting of Black and Latio young men.\nStudies have shown that this has led to mistrust in the police.\n\n\n\nA bit about me\nI’m not Black.\nI’m am Hispanic.\nI am not from New York City.\n\n\n\n\n\nRace Exists\nLet’s acknowledge that Race exists and plays a part in the way human being interact with each other.\nWe might get a bit uncomfortable.\n\n\nSchedule:\n\n\nIntroduce you to the data.\nPose a question that I have about stop and frisk.\nGive you Data Frames with data to answer the question one way.\n\nYou’ll order them with a partner.\nYou’ll make up puesdo code to explain data transformations.\nI’ll give you the real code arrows.\n\nWe’ll repeat the process of data transformation with the real code.\nTime for questions.\n\n\n\n\nQuestions so far?\n\n\nThe Data\nHere’s NYC’s website with the stop and frisk data.\n\n\nEach column is a variable\nand each row is a stop\n\n\nData Dictionaries exist for older data.\nNew Data variables are more clear.\nThe variable names are inconsistent across years.\n\n\nA Question\n\nAre Black, Hispanic, groups more likely to be stopped by police officers than other groups in 2011? Does this change as the total counts of stops decreases to 2021 levels?\n\n\n\nMotivation for question\nThis Stop and Frisk policing strategy came into force under Michael Bloomberg governor from 2003 to 2013.\nDuring the end of Michael Bloomberg’s tenure as governor there was a public out cry of the ____ of this policy.\nThe policy’s discrimination leads to distrust in police.\n\n\nStops in a year\n\n# Read in each csv file. This is a lot \n\n# With purr csv\n\nfile_paths_csv <- fs::dir_ls(\"../data/2003_2015_csv_files\")\n\nfile_contents_csv<- file_paths_csv |>\n  map(function (path){\n    read_csv(path)\n  })\n\n# with purr excel\n\nfile_paths_xl <- fs::dir_ls(\"../data/2016_2022_xl_files\")\n\nfile_contents_xl<- file_paths_xl |>\n  map(function (path){\n    read_excel(path)\n  })\n\n# https://www.youtube.com/watch?v=An1bUIg-nVM\n\n#See the number of rows i.e stops in each year\npre_2016 <- sapply(file_contents_csv, nrow)\npost_2016 <- sapply(file_contents_xl, nrow)\n\n\nyears <- c(2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022 )\nstops_frisks <- c(160851, 313523, 398191, 506491, 472096, 540302, 581168,  601285, 685724, 532911,  191851, 45787, 22563, 12405, 11629,  11008,   13459,9544 , 8947,  15102)  \n\nsqf <- as.data.frame(years,stops_frisks)\n\nWarning in as.data.frame.numeric(years, stops_frisks): 'row.names' is not a\ncharacter vector of length 20 -- omitting it. Will be an error!\n\nsqf |> \n  ggplot(aes(years,stops_frisks)) +\n  geom_line()+\n  xlab(\"Year\")+\n  ylab(\"Citizens Stopped ('000s)\")+\n  labs(title=\"\")+\n  theme_minimal()+\n  scale_y_continuous(breaks = c(0,350000,700000), labels = c(\"0\",\"350\",\"700\"))+\n  scale_x_continuous(breaks = c(2003,2013,2022))\n\n\n\n\n\n\nLet’s take a look at the data frame together.\n\n\nHere are your data frames\nLittle envelopes Data 2021\nLittle envelopes Functions\n\n\nConclusions from 2021 data\n\n\nFor comparison:\nHere’s the demographics of NYC1:\n\nBlack: 23.4 %\nLatino: 28.9%\nWhite: 39.8%\n\n\n\nSummarize functions:\nNew functions:\nselect(), mutate(), arrange(), rename()\nOld funtions:\nnames(), recode(), count()\n\n\nLet’s compare to 2011.\nMake a new r project.\nDownload 2011 csv from this site. Extract it to the same folder as your rproj.\nMake a new document and put this in a chunk.\nread_csv(\"2011.csv\")\n\n\nAnswer the question.\n\nAre Black, Hispanic, groups more likely to be stopped by police officers than other groups in 2011? Does this change as the total counts of stops decreases to 2021 levels?\n\n\n\nWhat other questions do you have about the data?\n\n\n\n\n\nFootnotes\n\n\nhttps://www.census.gov/quickfacts/fact/table/newyorkcitynewyork/PST045222↩︎"
  },
  {
    "objectID": "course-materials/lectures/mdsr-the-verbs.html#dplyr-lives-in-the-tidyverse",
    "href": "course-materials/lectures/mdsr-the-verbs.html#dplyr-lives-in-the-tidyverse",
    "title": "The Verbs",
    "section": "dplyr lives in the tidyverse",
    "text": "dplyr lives in the tidyverse"
  },
  {
    "objectID": "course-materials/lectures/mdsr-the-verbs.html#dplyr-highlights",
    "href": "course-materials/lectures/mdsr-the-verbs.html#dplyr-highlights",
    "title": "The Verbs",
    "section": "dplyr highlights",
    "text": "dplyr highlights\n\n\nThe Five Verbs:\n\nselect()\nfilter()\nmutate()\narrange()\nsummarize()\n\n\nPlus:\n\ngroup_by()\nrename()\ninner_join()\nleft_join()\n\n\n\nRead more"
  },
  {
    "objectID": "course-materials/lectures/mdsr-the-verbs.html#philosophy",
    "href": "course-materials/lectures/mdsr-the-verbs.html#philosophy",
    "title": "The Verbs",
    "section": "Philosophy",
    "text": "Philosophy\n\nEach verb takes a data frame and returns a data frame\n\nactually a tbl_df (more on that later)\nallows chaining with %&gt;% or |&gt;\n\nIdea:\n\nmaster a few simple commands\nuse your creativity to combine them\n\nCheat Sheet:\n\nResources tab"
  },
  {
    "objectID": "course-materials/lectures/mdsr-the-verbs.html#what-is-a-tibble",
    "href": "course-materials/lectures/mdsr-the-verbs.html#what-is-a-tibble",
    "title": "The Verbs",
    "section": "What is a tibble?",
    "text": "What is a tibble?\n\n\n\n\n\nobject of class tbl\na re-imagining of a data.frame\nit looks and acts like a data.frame\nbut it’s even better…\ntidyverse works with tibbles\n\n\n\nfootnote"
  },
  {
    "objectID": "course-materials/lectures/mdsr-the-verbs.html#select-take-a-subset-of-the-columns",
    "href": "course-materials/lectures/mdsr-the-verbs.html#select-take-a-subset-of-the-columns",
    "title": "The Verbs",
    "section": "select(): take a subset of the columns",
    "text": "select(): take a subset of the columns"
  },
  {
    "objectID": "course-materials/lectures/mdsr-the-verbs.html#filter-take-a-subset-of-the-rows",
    "href": "course-materials/lectures/mdsr-the-verbs.html#filter-take-a-subset-of-the-rows",
    "title": "The Verbs",
    "section": "filter(): take a subset of the rows",
    "text": "filter(): take a subset of the rows"
  },
  {
    "objectID": "course-materials/lectures/mdsr-the-verbs.html#mutate-add-or-modify-a-column",
    "href": "course-materials/lectures/mdsr-the-verbs.html#mutate-add-or-modify-a-column",
    "title": "The Verbs",
    "section": "mutate(): add or modify a column",
    "text": "mutate(): add or modify a column"
  },
  {
    "objectID": "course-materials/lectures/mdsr-the-verbs.html#arrange-sort-the-rows",
    "href": "course-materials/lectures/mdsr-the-verbs.html#arrange-sort-the-rows",
    "title": "The Verbs",
    "section": "arrange(): sort the rows",
    "text": "arrange(): sort the rows"
  },
  {
    "objectID": "course-materials/lectures/mdsr-the-verbs.html#summarize-collapse-to-a-single-row",
    "href": "course-materials/lectures/mdsr-the-verbs.html#summarize-collapse-to-a-single-row",
    "title": "The Verbs",
    "section": "summarize(): collapse to a single row",
    "text": "summarize(): collapse to a single row"
  },
  {
    "objectID": "course-materials/in-class-activies/Activity_Taxonomy_of_Graphics.html",
    "href": "course-materials/in-class-activies/Activity_Taxonomy_of_Graphics.html",
    "title": "Taxonomy of Graphics",
    "section": "",
    "text": "Use the vocabulary from the Taxonomy of data graphics.\n\n\nvisual cues\ncoordinate system\nscales\ncontext\nWhat is the graph showing?\nYour feelings"
  },
  {
    "objectID": "course-materials/in-class-activies/Activity_Taxonomy_of_Graphics.html#discuss-the-following",
    "href": "course-materials/in-class-activies/Activity_Taxonomy_of_Graphics.html#discuss-the-following",
    "title": "Taxonomy of Graphics",
    "section": "",
    "text": "Use the vocabulary from the Taxonomy of data graphics.\n\n\nvisual cues\ncoordinate system\nscales\ncontext\nWhat is the graph showing?\nYour feelings"
  },
  {
    "objectID": "course-materials/in-class-activies/Activity_Taxonomy_of_Graphics.html#ny-times-graphs",
    "href": "course-materials/in-class-activies/Activity_Taxonomy_of_Graphics.html#ny-times-graphs",
    "title": "Taxonomy of Graphics",
    "section": "NY Times Graphs:",
    "text": "NY Times Graphs:\n\nSerena Williams\nEndangered Biodiversity\nPandemic Stimulus"
  },
  {
    "objectID": "course-materials/in-class-activies/Activity_Taxonomy_of_Graphics.html#yougov",
    "href": "course-materials/in-class-activies/Activity_Taxonomy_of_Graphics.html#yougov",
    "title": "Taxonomy of Graphics",
    "section": "Yougov:",
    "text": "Yougov:\n\nIce Cream (Just the first graph, there is a lot here)."
  },
  {
    "objectID": "course-materials/in-class-activies/Activity_Taxonomy_of_Graphics.html#from-five-thirty-eight",
    "href": "course-materials/in-class-activies/Activity_Taxonomy_of_Graphics.html#from-five-thirty-eight",
    "title": "Taxonomy of Graphics",
    "section": "From Five Thirty Eight:",
    "text": "From Five Thirty Eight:\nPresident Biden’s Approval Rating"
  },
  {
    "objectID": "course-materials/in-class-activies/Activity_Taxonomy_of_Graphics.html#plan-parenthood",
    "href": "course-materials/in-class-activies/Activity_Taxonomy_of_Graphics.html#plan-parenthood",
    "title": "Taxonomy of Graphics",
    "section": "Plan Parenthood:",
    "text": "Plan Parenthood:"
  },
  {
    "objectID": "course-materials/in-class-activies/Activity_Taxonomy_of_Graphics.html#corrected",
    "href": "course-materials/in-class-activies/Activity_Taxonomy_of_Graphics.html#corrected",
    "title": "Taxonomy of Graphics",
    "section": "Corrected",
    "text": "Corrected"
  },
  {
    "objectID": "course-materials/in-class-activies/Activity_Taxonomy_of_Graphics.html#corrected-again",
    "href": "course-materials/in-class-activies/Activity_Taxonomy_of_Graphics.html#corrected-again",
    "title": "Taxonomy of Graphics",
    "section": "Corrected again",
    "text": "Corrected again"
  },
  {
    "objectID": "course-materials/in-class-activies/Activity_Taxonomy_of_Graphics.html#fox-polling",
    "href": "course-materials/in-class-activies/Activity_Taxonomy_of_Graphics.html#fox-polling",
    "title": "Taxonomy of Graphics",
    "section": "Fox Polling",
    "text": "Fox Polling"
  },
  {
    "objectID": "course-materials/in-class-activies/Activity_Taxonomy_of_Graphics.html#global-warming",
    "href": "course-materials/in-class-activies/Activity_Taxonomy_of_Graphics.html#global-warming",
    "title": "Taxonomy of Graphics",
    "section": "Global warming",
    "text": "Global warming"
  },
  {
    "objectID": "course-materials/in-class-activies/Activity_Taxonomy_of_Graphics.html#global-warming-2",
    "href": "course-materials/in-class-activies/Activity_Taxonomy_of_Graphics.html#global-warming-2",
    "title": "Taxonomy of Graphics",
    "section": "Global warming 2",
    "text": "Global warming 2"
  },
  {
    "objectID": "course-materials/in-class-activies/Activity_Taxonomy_of_Graphics.html#global-warming-3",
    "href": "course-materials/in-class-activies/Activity_Taxonomy_of_Graphics.html#global-warming-3",
    "title": "Taxonomy of Graphics",
    "section": "Global Warming 3",
    "text": "Global Warming 3"
  },
  {
    "objectID": "course-materials/in-class-activies/Activity_Taxonomy_of_Graphics.html#global-warming-4",
    "href": "course-materials/in-class-activies/Activity_Taxonomy_of_Graphics.html#global-warming-4",
    "title": "Taxonomy of Graphics",
    "section": "Global Warming 4",
    "text": "Global Warming 4\n ## Gun Deaths Florida"
  },
  {
    "objectID": "course-materials/in-class-activies/Activity_Taxonomy_of_Graphics.html#citations",
    "href": "course-materials/in-class-activies/Activity_Taxonomy_of_Graphics.html#citations",
    "title": "Taxonomy of Graphics",
    "section": "Citations",
    "text": "Citations\nAll graph originated else where.\nBelow are secondary sources.\nMost the the graphs were grabed from: datapipeline\nThe last graph was grabbed from The Washington Post"
  },
  {
    "objectID": "course-materials/in-class-activies/Wrangling_Baby_Names.html",
    "href": "course-materials/in-class-activies/Wrangling_Baby_Names.html",
    "title": "Wrangle Babynamnes",
    "section": "",
    "text": "We will work with the five verbs to wrangle and graph babynames.\nYou should check out the dplyr cheatsheet.\nThere are three parts to today’s classwork.\n\nPart 1. make a narcissistic graph\nPart 2. 5 most popular names in the US since 1880\nPart 3. Do presidents’ names influence babies’ names?"
  },
  {
    "objectID": "course-materials/in-class-activies/Wrangling_Baby_Names.html#this-is-not-a-lab",
    "href": "course-materials/in-class-activies/Wrangling_Baby_Names.html#this-is-not-a-lab",
    "title": "Wrangle Babynamnes",
    "section": "",
    "text": "We will work with the five verbs to wrangle and graph babynames.\nYou should check out the dplyr cheatsheet.\nThere are three parts to today’s classwork.\n\nPart 1. make a narcissistic graph\nPart 2. 5 most popular names in the US since 1880\nPart 3. Do presidents’ names influence babies’ names?"
  },
  {
    "objectID": "course-materials/in-class-activies/Wrangling_Baby_Names.html#wrangle-your-name-out-of-babynames",
    "href": "course-materials/in-class-activies/Wrangling_Baby_Names.html#wrangle-your-name-out-of-babynames",
    "title": "Wrangle Babynamnes",
    "section": "1. Wrangle your name out of babynames",
    "text": "1. Wrangle your name out of babynames\nYou will want to filter() your name. I would make a vector of names c(“Nic”,“Nicholas”, “Nick”)\nConsider if you want both the sex= M and F."
  },
  {
    "objectID": "course-materials/in-class-activies/Wrangling_Baby_Names.html#create-a-line-graph",
    "href": "course-materials/in-class-activies/Wrangling_Baby_Names.html#create-a-line-graph",
    "title": "Wrangle Babynamnes",
    "section": "2. Create a line graph",
    "text": "2. Create a line graph\nShow the proportion of children with the same names as you over time."
  },
  {
    "objectID": "index.html#project-1",
    "href": "index.html#project-1",
    "title": "SDS 192: Intro to Data Science",
    "section": "Project 1",
    "text": "Project 1\nProject 1 Data Dictionary\nPolishing Figures\n\n\n\n\n\n\nworking directory\n\n\n\n\n\nYou may need to set your working directory.\nThe easiest way to do this is to find your Lec09-…zip in the file pane and go gear-icon &gt; “Set As Working Directory”"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "SDS 192: Intro to Data Science",
    "section": "",
    "text": "Schedule\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n–&gt;\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDay 1: No Computer Data Viz\n\nSyllabus\nLog into Slack\nWebsite tour\nBring Computers to Class\n\n\nLecture\nData Viz No Computers\n\n\nGeneral Questions and Comments\n\n\n\n\n\n\nHomework:\n\n\n\n\n\n\nSign up for github here, if you don’t already have an account. We will very carefully link your github account to our github classroom account.\nRead the prologue to chapter 1.4 of MDSR.\n\n\n\n\n\n\nWalk to MCConnell 213 and 214\nMy office and group study room."
  },
  {
    "objectID": "course-materials/lectures/Day18_pivots.html",
    "href": "course-materials/lectures/Day18_pivots.html",
    "title": "Tidydata and pivots",
    "section": "",
    "text": "Tidydata\n\n\n\nI have heard about\npivot_longer()\npivot_wider()\nWhat do these functions do?\n\n\n10 minutes for pivot_longer()\nThis data is not tidy how can we make it longer for computers?\n\n\n✔ Reading from \"indicator hiv estimated prevalence% 15-49\".\n\n\n✔ Range 'Data'.\n\n\n# A tibble: 3 × 5\n  Country        `1979` `1989` `1999` `2009`\n  &lt;chr&gt;           &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n1 France        NA          NA    0.3    0.4\n2 South Africa  NA          NA   14.8   17.2\n3 United States  0.0318     NA    0.5    0.6\n\n\nWrite down how you think we could do that with pivot_longer()\n\n\n10 minutes pivot_wider()\nThis data is tidy how could we make it wider for humans?\n\n\n`summarise()` has grouped output by 'name'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 6 × 3\n# Groups:   name [3]\n  name   sex    total\n  &lt;chr&gt;  &lt;chr&gt;  &lt;int&gt;\n1 Leslie F     266474\n2 Leslie M     112689\n3 Robin  F     289395\n4 Robin  M      44616\n5 Sue    F     144465\n6 Sue    M        519\n\n\nWrite down how you think we could do that with pivot_wider()\n\n\nEnd of slides\n\n\nReally End of Slides\n\n\nJust kidding pivot_longer()\nLet’s try our code on the examples above. Pivot this longer.\n\nlibrary(tidyverse)\nlibrary(mdsr)\nlibrary(googlesheets4)\ngs4_deauth()\nhiv_key &lt;- \"1kWH_xdJDM4SMfT_Kzpkk-1yuxWChfurZuWYjfmv51EA\"\nhiv &lt;- read_sheet(hiv_key) |&gt;\n  rename(Country = 1) |&gt;\n  filter(\n    Country %in% c(\"United States\", \"France\", \"South Africa\")\n  ) |&gt;\n  select(Country, `1979`, `1989`, `1999`, `2009`) |&gt;\n  unnest(cols = c(`2009`)) |&gt;\n  mutate(across(matches(\"[0-9]\"), as.double))\n\n✔ Reading from \"indicator hiv estimated prevalence% 15-49\".\n\n\n✔ Range 'Data'.\n\nhiv\n\n# A tibble: 3 × 5\n  Country        `1979` `1989` `1999` `2009`\n  &lt;chr&gt;           &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n1 France        NA          NA    0.3    0.4\n2 South Africa  NA          NA   14.8   17.2\n3 United States  0.0318     NA    0.5    0.6\n\n\n\n\npivot_wider()\n\nlibrary(babynames)\nbabynames |&gt;\n     filter(name %in% c(\"Sue\", \"Robin\", \"Leslie\")) |&gt;\n     group_by(name, sex) |&gt;\n     summarize(total = sum(n))\n\n`summarise()` has grouped output by 'name'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 6 × 3\n# Groups:   name [3]\n  name   sex    total\n  &lt;chr&gt;  &lt;chr&gt;  &lt;int&gt;\n1 Leslie F     266474\n2 Leslie M     112689\n3 Robin  F     289395\n4 Robin  M      44616\n5 Sue    F     144465\n6 Sue    M        519\n\n\n\n\nFurther Reading\n[Futher reading on tidy data](https://r4ds.had.co.nz/tidy-data.html)\n[H]"
  },
  {
    "objectID": "course-materials/lectures/Day20_tidying.html",
    "href": "course-materials/lectures/Day20_tidying.html",
    "title": "Cleaning Data",
    "section": "",
    "text": "Data is Messy.\nWe have to clean other people’s data.\n\n\nLubridate\nCleans dates for us. cheat-sheet\nymd(),mdy()\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.3     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.3     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(lubridate)\n\nhead(lakers,3)\n\n      date opponent game_type  time period     etype team              player\n1 20081028      POR      home 12:00      1 jump ball  OFF                    \n2 20081028      POR      home 11:39      1      shot  LAL           Pau Gasol\n3 20081028      POR      home 11:37      1   rebound  LAL Vladimir Radmanovic\n  result points type  x  y\n1             0      NA NA\n2 missed      0 hook 23 13\n3             0  off NA NA\n\n\n\n\nlakers$date\n\ntypeof(lakers$date)\n\n[1] \"integer\"\n\n\n\n# Let's make this into a time object.\nlakers$date &lt;-ymd(lakers$date)\ntypeof(lakers$date)\n\n[1] \"double\""
  },
  {
    "objectID": "course-materials/in-class-activies/Lec17In-classExercise-JoinTables/Lec17In-classExercise-JoinTables.html",
    "href": "course-materials/in-class-activies/Lec17In-classExercise-JoinTables/Lec17In-classExercise-JoinTables.html",
    "title": "Lec 17: In-class Exercise: Join Two Tables",
    "section": "",
    "text": "The ct_school_attendance dataset documents school attendance in 2019-2020 and 2020-2021 by Connecticut school district. Certain rows documents attendance rates for “All students”, while others report the data for certain student groups including:\nStudents experiencing homelessness Students with disabilities Students who qualify for free/reduced lunch English learners All high needs students Non-high needs students Students by race/ethnicity (Hispanic/Latino of any race, Black or African American, White, All other races)\nFinally, there is a series of rows in the dataset that document attendance rates for all of Connecticut.\nTo standardize the observations under consideration, we will start by reading in the data and filtering to rows documenting attendance rates for all students and rows not documenting attendance rates for all of Connecticut.\n\nlibrary(tidyverse)\n\nct_school_attendance &lt;- read_csv(\"data/ct_school_attendance.csv\") |&gt;\n  filter(studentgroup == \"All Students\" & reportingdistrictname != \"Connecticut\") \n\nThe ct_school_learning_model dataset documents information about the percentage of students engaged in remote learning during each week of the year by Connecticut school district. We will only consider the remote learning percentages in the first week of most schools’ 2020-2021 school year: September 7, 2020 - September 11, 2020.\n\nct_school_learning_model &lt;-\n  read_csv(\"data/ct_school_learning_model.csv\")\n\n\nStep 1: Inner Join\n\nJoin ct_school_attendance by ct_school_learning_model with an inner join.\nselect() the district code, the district name, the 2020-2021 attendance rate, and the percent of students that are fully remote in the first week of the 2020-2021 school year.\n\n\n# Write your code below\nct_school_attendance |&gt;\ninner_join( ct_school_learning_model, by= c(\"reportingdistrictcode\"=\"district_code\") )\n\n# A tibble: 197 × 24\n   reportingdistrictcode reportingdistrictname       category studentgroup\n   &lt;chr&gt;                 &lt;chr&gt;                       &lt;chr&gt;    &lt;chr&gt;       \n 1 0010011               Andover School District     &lt;NA&gt;     All Students\n 2 0020011               Ansonia School District     &lt;NA&gt;     All Students\n 3 0030011               Ashford School District     &lt;NA&gt;     All Students\n 4 0040011               Avon School District        &lt;NA&gt;     All Students\n 5 0050011               Barkhamsted School District &lt;NA&gt;     All Students\n 6 0070011               Berlin School District      &lt;NA&gt;     All Students\n 7 0080011               Bethany School District     &lt;NA&gt;     All Students\n 8 0090011               Bethel School District      &lt;NA&gt;     All Students\n 9 0110011               Bloomfield School District  &lt;NA&gt;     All Students\n10 0120011               Bolton School District      &lt;NA&gt;     All Students\n# ℹ 187 more rows\n# ℹ 20 more variables: studentcount_current &lt;dbl&gt;, attrate_ytd &lt;dbl&gt;,\n#   studentcount_202021 &lt;dbl&gt;, attrate_202021 &lt;dbl&gt;, studentcount_201920 &lt;dbl&gt;,\n#   attrate_201920 &lt;dbl&gt;, reportingperiod &lt;dttm&gt;, date_update &lt;dttm&gt;,\n#   district_name &lt;chr&gt;, school_start_date &lt;dttm&gt;, grades_inperson_model &lt;chr&gt;,\n#   grades_hybrid_model &lt;chr&gt;, grades_remote_model &lt;chr&gt;,\n#   percent_students_fully_remote &lt;chr&gt;, total_number_students &lt;chr&gt;, …\n\n\nQuestion: How many rows are in the resulting table?\nAnswer: 197\n\n\nStep 2a: Left Join\n\nCopy your code above into the chunk below, and change it to a left join.\n\n\n# Paste the code below and adjust it\nct_school_attendance |&gt;\nleft_join( ct_school_learning_model, by= c(\"reportingdistrictcode\"=\"district_code\") )\n\n# A tibble: 200 × 24\n   reportingdistrictcode reportingdistrictname       category studentgroup\n   &lt;chr&gt;                 &lt;chr&gt;                       &lt;chr&gt;    &lt;chr&gt;       \n 1 0010011               Andover School District     &lt;NA&gt;     All Students\n 2 0020011               Ansonia School District     &lt;NA&gt;     All Students\n 3 0030011               Ashford School District     &lt;NA&gt;     All Students\n 4 0040011               Avon School District        &lt;NA&gt;     All Students\n 5 0050011               Barkhamsted School District &lt;NA&gt;     All Students\n 6 0070011               Berlin School District      &lt;NA&gt;     All Students\n 7 0080011               Bethany School District     &lt;NA&gt;     All Students\n 8 0090011               Bethel School District      &lt;NA&gt;     All Students\n 9 0110011               Bloomfield School District  &lt;NA&gt;     All Students\n10 0120011               Bolton School District      &lt;NA&gt;     All Students\n# ℹ 190 more rows\n# ℹ 20 more variables: studentcount_current &lt;dbl&gt;, attrate_ytd &lt;dbl&gt;,\n#   studentcount_202021 &lt;dbl&gt;, attrate_202021 &lt;dbl&gt;, studentcount_201920 &lt;dbl&gt;,\n#   attrate_201920 &lt;dbl&gt;, reportingperiod &lt;dttm&gt;, date_update &lt;dttm&gt;,\n#   district_name &lt;chr&gt;, school_start_date &lt;dttm&gt;, grades_inperson_model &lt;chr&gt;,\n#   grades_hybrid_model &lt;chr&gt;, grades_remote_model &lt;chr&gt;,\n#   percent_students_fully_remote &lt;chr&gt;, total_number_students &lt;chr&gt;, …\n\n\nQuestion: How many rows are in the resulting table?\nAnswer: 200\n\n\nStep 2b\n\nCopy the code above into the chunk below, and filter to the rows where percent_students_fully_remote is NA.\n\n\n# Paste the code below and adjust it\nct_school_attendance |&gt;\nleft_join( ct_school_learning_model, by= c(\"reportingdistrictcode\"=\"district_code\") ) |&gt;\n  filter(is.na(percent_students_fully_remote))\n\n# A tibble: 3 × 24\n  reportingdistrictcode reportingdistrictname              category studentgroup\n  &lt;chr&gt;                 &lt;chr&gt;                              &lt;chr&gt;    &lt;chr&gt;       \n1 2310018               Goodwin University Educational Se… &lt;NA&gt;     All Students\n2 3360015               Unified School District #1         &lt;NA&gt;     All Students\n3 3470015               Unified School District #2         &lt;NA&gt;     All Students\n# ℹ 20 more variables: studentcount_current &lt;dbl&gt;, attrate_ytd &lt;dbl&gt;,\n#   studentcount_202021 &lt;dbl&gt;, attrate_202021 &lt;dbl&gt;, studentcount_201920 &lt;dbl&gt;,\n#   attrate_201920 &lt;dbl&gt;, reportingperiod &lt;dttm&gt;, date_update &lt;dttm&gt;,\n#   district_name &lt;chr&gt;, school_start_date &lt;dttm&gt;, grades_inperson_model &lt;chr&gt;,\n#   grades_hybrid_model &lt;chr&gt;, grades_remote_model &lt;chr&gt;,\n#   percent_students_fully_remote &lt;chr&gt;, total_number_students &lt;chr&gt;,\n#   predominant_model &lt;lgl&gt;, organization_type &lt;chr&gt;, …\n\n\nQuestion: Why is there missing data in these rows?\nAnswer:\n\n\nStep 3a: Right Join\n\nCopy your code above into the chunk below, and change it to a right join.\n\n\n# Paste the code below and adjust it\nct_school_attendance |&gt;\nright_join( ct_school_learning_model, by= c(\"reportingdistrictcode\"=\"district_code\") ) |&gt;\n  filter(is.na(percent_students_fully_remote))\n\n# A tibble: 5 × 24\n  reportingdistrictcode reportingdistrictname category studentgroup\n  &lt;chr&gt;                 &lt;chr&gt;                 &lt;chr&gt;    &lt;chr&gt;       \n1 0646161               &lt;NA&gt;                  &lt;NA&gt;     &lt;NA&gt;        \n2 0740161               &lt;NA&gt;                  &lt;NA&gt;     &lt;NA&gt;        \n3 0950161               &lt;NA&gt;                  &lt;NA&gt;     &lt;NA&gt;        \n4 1410161               &lt;NA&gt;                  &lt;NA&gt;     &lt;NA&gt;        \n5 1550361               &lt;NA&gt;                  &lt;NA&gt;     &lt;NA&gt;        \n# ℹ 20 more variables: studentcount_current &lt;dbl&gt;, attrate_ytd &lt;dbl&gt;,\n#   studentcount_202021 &lt;dbl&gt;, attrate_202021 &lt;dbl&gt;, studentcount_201920 &lt;dbl&gt;,\n#   attrate_201920 &lt;dbl&gt;, reportingperiod &lt;dttm&gt;, date_update &lt;dttm&gt;,\n#   district_name &lt;chr&gt;, school_start_date &lt;dttm&gt;, grades_inperson_model &lt;chr&gt;,\n#   grades_hybrid_model &lt;chr&gt;, grades_remote_model &lt;chr&gt;,\n#   percent_students_fully_remote &lt;chr&gt;, total_number_students &lt;chr&gt;,\n#   predominant_model &lt;lgl&gt;, organization_type &lt;chr&gt;, …\n\n\nQuestion: How many rows are in the resulting table?\nAnswer: 5\n\n\nStep 3b\n\nCopy the code above into the chunk below, and filter to the rows where reportingdistrictname is NA.\n\n\n# Paste the code below and adjust it\nct_school_attendance |&gt;\nright_join( ct_school_learning_model, by= c(\"reportingdistrictcode\"=\"district_code\") ) |&gt;\n  filter(is.na(reportingdistrictname))\n\n# A tibble: 88 × 24\n   reportingdistrictcode reportingdistrictname category studentgroup\n   &lt;chr&gt;                 &lt;chr&gt;                 &lt;chr&gt;    &lt;chr&gt;       \n 1 0046821               &lt;NA&gt;                  &lt;NA&gt;     &lt;NA&gt;        \n 2 0046921               &lt;NA&gt;                  &lt;NA&gt;     &lt;NA&gt;        \n 3 0100161               &lt;NA&gt;                  &lt;NA&gt;     &lt;NA&gt;        \n 4 0170561               &lt;NA&gt;                  &lt;NA&gt;     &lt;NA&gt;        \n 5 0170821               &lt;NA&gt;                  &lt;NA&gt;     &lt;NA&gt;        \n 6 0190161               &lt;NA&gt;                  &lt;NA&gt;     &lt;NA&gt;        \n 7 0230121               &lt;NA&gt;                  &lt;NA&gt;     &lt;NA&gt;        \n 8 0250161               &lt;NA&gt;                  &lt;NA&gt;     &lt;NA&gt;        \n 9 0330161               &lt;NA&gt;                  &lt;NA&gt;     &lt;NA&gt;        \n10 0360161               &lt;NA&gt;                  &lt;NA&gt;     &lt;NA&gt;        \n# ℹ 78 more rows\n# ℹ 20 more variables: studentcount_current &lt;dbl&gt;, attrate_ytd &lt;dbl&gt;,\n#   studentcount_202021 &lt;dbl&gt;, attrate_202021 &lt;dbl&gt;, studentcount_201920 &lt;dbl&gt;,\n#   attrate_201920 &lt;dbl&gt;, reportingperiod &lt;dttm&gt;, date_update &lt;dttm&gt;,\n#   district_name &lt;chr&gt;, school_start_date &lt;dttm&gt;, grades_inperson_model &lt;chr&gt;,\n#   grades_hybrid_model &lt;chr&gt;, grades_remote_model &lt;chr&gt;,\n#   percent_students_fully_remote &lt;chr&gt;, total_number_students &lt;chr&gt;, …\n\n\nQuestion: Why is there missing data in these rows?\nAnswer:\n\n\nStep 4a: Full Join\n\nCopy your code above into the chunk below, and change it to a full join.\n\n\n# Paste the code below and adjust it\n\nQuestion: How many rows are in the resulting table?\nAnswer:\n\n\nStep 4b\n\nCopy the code above into the chunk below, and filter to the rows where reportingdistrictname OR percent_students_fully_remote is NA.\n\n\n# Paste the code below and adjust it\n\nQuestion: Why is there missing data in these rows?\nAnswer:\n\n\nBonus! Is there a correlation between the percent of students fully remote in the first week of the 2020-2021 CT school year and the 2020-2021 attendance rate? Create a scatterplot to visualize this.\n\nHint: You are going to have to clean up the percent_students_fully_remote by converting asterisks to NA, removing the percentage sign, converting to integer, and dividing the number by 100.\n\n\n# Write your code below"
  },
  {
    "objectID": "course-materials/lectures/functions.html",
    "href": "course-materials/lectures/functions.html",
    "title": "Making Functions practice",
    "section": "",
    "text": "Functions\n\nInputs and outputs\nCan set defaults arguements\nCan be general or specific to a package.\n\nn() vs. read_all_contributions()\n\nSave time in the long run.\n\n\n\nFunction outline\n\nGreeting &lt;- function(arg1 = \"Hello\" ){\n  print(arg1)\n}\nGreeting()\n\n[1] \"Hello\"\n\nGreeting(\"Hiya\")\n\n[1] \"Hiya\"\n\n\n\n\nThis function will add\n\nadding &lt;- function(x,y){\n  \n  total &lt;- sum( c( x , y ))\n  \n  return(total)\n}\n\nadding(2,4)\n\n[1] 6\n\n#adding()\n\n\n\nThis function will multiply\n\nmultiplying &lt;- function(x = 1, y = 1){\n  total &lt;- x*y\n  return(total)\n}\n\nmultiplying()\n\n[1] 1\n\nmultiplying(2,4)\n\n[1] 8\n\n\n\n\nif, else if, else\nThe computer can run a logical check.\nConsider this function:\n\numbrella &lt;- function(weather = \"no precipitation\"){\n\nif(weather == \"no precipitation\"){\n  \n    print(\"leave umbrella at home\")\n    }\n    \nelse if(weather == \"snow\"){\n\n    print(\"You don't need an umbrella\")\n}\n  \nelse{\n    print(\"bring an umbrella\")\n    \n    }\n}\numbrella(weather = \"snow\")\n\n[1] \"You don't need an umbrella\"\n\n\n\n\nThis is a composite function\nDepending in an argument\n\nmy_1st_calculator &lt;-function(x,y,operation=\"add\"){\n  \n  if(operation %in% \"add\"){\n    total &lt;- adding(x,y)\n  }\n  \n  else if(operation %in% \"multiply\"){\n    total &lt;- multiplying(x,y)\n  }\n  \n  else{\n    stop(\"Please choose `add` or `multiply` for the operation argument\")\n  }\n  \n  return(total)\n}\n\n\nmy_1st_calculator(1,6, operation=\"multiply\")\n\n[1] 6\n\n\n\n\nNote on data masking\nNo masking : data$variable\nWith masking : data |&gt; filter(variable)\nData masking is super convenient for learning the tidyverse.\nNot so great when making functions.\nIf using a tidyverse verb with a variable use {{}} around the variable.\nRead more\n\n\nFiltering a lot\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.3     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.3     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nauto_filter &lt;- function(data, variable, value){\n  \n  data |&gt;\n    filter({{variable}} == {{value}})\n}\n\n\nauto_filter(data = mtcars, variable = am, value = 0 )\n\n                     mpg cyl  disp  hp drat    wt  qsec vs am gear carb\nHornet 4 Drive      21.4   6 258.0 110 3.08 3.215 19.44  1  0    3    1\nHornet Sportabout   18.7   8 360.0 175 3.15 3.440 17.02  0  0    3    2\nValiant             18.1   6 225.0 105 2.76 3.460 20.22  1  0    3    1\nDuster 360          14.3   8 360.0 245 3.21 3.570 15.84  0  0    3    4\nMerc 240D           24.4   4 146.7  62 3.69 3.190 20.00  1  0    4    2\nMerc 230            22.8   4 140.8  95 3.92 3.150 22.90  1  0    4    2\nMerc 280            19.2   6 167.6 123 3.92 3.440 18.30  1  0    4    4\nMerc 280C           17.8   6 167.6 123 3.92 3.440 18.90  1  0    4    4\nMerc 450SE          16.4   8 275.8 180 3.07 4.070 17.40  0  0    3    3\nMerc 450SL          17.3   8 275.8 180 3.07 3.730 17.60  0  0    3    3\nMerc 450SLC         15.2   8 275.8 180 3.07 3.780 18.00  0  0    3    3\nCadillac Fleetwood  10.4   8 472.0 205 2.93 5.250 17.98  0  0    3    4\nLincoln Continental 10.4   8 460.0 215 3.00 5.424 17.82  0  0    3    4\nChrysler Imperial   14.7   8 440.0 230 3.23 5.345 17.42  0  0    3    4\nToyota Corona       21.5   4 120.1  97 3.70 2.465 20.01  1  0    3    1\nDodge Challenger    15.5   8 318.0 150 2.76 3.520 16.87  0  0    3    2\nAMC Javelin         15.2   8 304.0 150 3.15 3.435 17.30  0  0    3    2\nCamaro Z28          13.3   8 350.0 245 3.73 3.840 15.41  0  0    3    4\nPontiac Firebird    19.2   8 400.0 175 3.08 3.845 17.05  0  0    3    2\n\n\n\n\nClasswork"
  },
  {
    "objectID": "course-materials/labs/lab6/across.html",
    "href": "course-materials/labs/lab6/across.html",
    "title": "SDS192 Lab 6",
    "section": "",
    "text": "In this lab, we will study the financial relationships between medical drug and device companies and certain healthcare providers in MA using the Center for Medicare and Medicaid Service’s Open Payments Dataset. Specifically, we will determine which ten Massachusetts-based doctors received the most money from medical drug or device manufacturers in 2021. Then we will leverage our custom functions to produce a number of tables and plots documenting information about the payments made to each of these doctors. In doing so, we will update a similar analysis produced by ProPublica in 2018 called Dollars for Docs."
  },
  {
    "objectID": "course-materials/labs/lab6/across.html#ex-1-unique-values",
    "href": "course-materials/labs/lab6/across.html#ex-1-unique-values",
    "title": "SDS192 Lab 6",
    "section": "Ex 1: Unique Values",
    "text": "Ex 1: Unique Values\nI’ve written a function below called num_unique. The function calculates the length of unique values in the vector passed to the argument x.\nBelow, I’ve selected the two columns in open_payments_cleaned that we want to iterate this function over. Determine which map() function to use in order to return a numeric vector that indicates the length of unique values in each of these columns. If you’ve done everything correctly, you should get the output below.\n\nnum_unique &lt;- function(x) {\n length(unique(x))\n}\n\nopen_payments_cleaned |&gt;\n  select(covered_recipient_npi, covered_recipient_full_name) |&gt;\n  map_int(num_unique) # Determine which map function to call here\n\n      covered_recipient_npi covered_recipient_full_name \n                      11837                       11858 \n\n\ncovered_recipient_npi covered_recipient_full_name\n11837 11858\nNotice that there are still more full names than covered_recipient_npis, which means that certain doctors have multiple names in this dataset. Below I’ve written some code to calculate the number unique full names listed for each covered_recipient_npi and filter to the rows with more than one name. Can you identify some reasons why we might have multiple names listed for this same medical practitioner in this data frame?\n\nopen_payments_cleaned |&gt;\n  group_by(covered_recipient_npi) |&gt;\n  mutate(num_names = length(unique(covered_recipient_full_name))) |&gt;\n  ungroup() |&gt;\n  filter(num_names &gt; 1) |&gt;\n  select(covered_recipient_npi, covered_recipient_full_name) |&gt;\n  distinct() |&gt;\n  arrange(desc(covered_recipient_npi))\n\n# A tibble: 292 × 2\n   covered_recipient_npi covered_recipient_full_name\n                   &lt;dbl&gt; &lt;chr&gt;                      \n 1            1992991657 LANA SCHUMACHER            \n 2            1992991657 LANA BEAL                  \n 3            1992932453 JESSICA ALLEGRETTI         \n 4            1992932453 JESSICA RAVIKOFF           \n 5            1992712178 PASI ANTERO JANNE          \n 6            1992712178 PASI JANNE                 \n 7            1992187132 FAIZ BAYO-AWOYEMI          \n 8            1992187132 FAIZ BAYO AWOYEMI          \n 9            1982680740 DONALD MARKS               \n10            1982680740 DON MARKS                  \n# ℹ 282 more rows\n\n\nIt could be a doctor’s maiden name that they have since changed. It could also be a misspelling or hypocorism. Because of these issues, it is important that we use the covered_recipient_npi to identify doctors vs. the full name."
  },
  {
    "objectID": "course-materials/labs/lab6/across.html#ex-2-top-10-doctors",
    "href": "course-materials/labs/lab6/across.html#ex-2-top-10-doctors",
    "title": "SDS192 Lab 6",
    "section": "Ex 2: Top 10 Doctors",
    "text": "Ex 2: Top 10 Doctors\nWrite code to determine the 10 medical practitioners that received the most money from drug and device manufacturers in 2021, and store your results in top_10_doctors. Your final data frame should have 10 rows and columns for covered_recipient_npi and sum_total_payments.\n\n# Uncomment below and write data wrangling code\n\ntop_10_doctors &lt;- open_payments_cleaned |&gt;\n  group_by(covered_recipient_npi) |&gt;\n  summarise(sum_total_payments = sum(total_amount_of_payment_usdollars)) |&gt;\n  arrange(desc(sum_total_payments))|&gt;\n  slice_max(order_by = sum_total_payments, n = 10)\n\ntop_10_doctors\n\n# A tibble: 10 × 2\n   covered_recipient_npi sum_total_payments\n                   &lt;dbl&gt;              &lt;dbl&gt;\n 1            1194763482          18755428.\n 2            1720096738          18751435 \n 3            1073561973           2112833.\n 4            1699732065           1869851.\n 5            1952351488            971882.\n 6            1194860205            971291.\n 7            1225124787            954938.\n 8            1164598801            820476.\n 9            1144267899            803031.\n10            1568424042            771362.\n\n\nRight now the values that we will eventually want to iterate over in our analysis are stored as columns in a data frame. …but the family of purrr functions allows us to apply a function to each element of a vector or list. We want to create a series of vectors from these columns that we can iterate over. We will use the pull() function to do this."
  },
  {
    "objectID": "course-materials/labs/lab6/across.html#ex-3-top-10-doctors-ids",
    "href": "course-materials/labs/lab6/across.html#ex-3-top-10-doctors-ids",
    "title": "SDS192 Lab 6",
    "section": "Ex 3: Top 10 Doctors IDs",
    "text": "Ex 3: Top 10 Doctors IDs\nCreate a vector of top_10_doctors_ids from top_10_doctors, using the pull() function.\n\n# Uncomment and write code below to pull the top 10 doctor IDs into a vector\n\ntop_10_doctors_ids &lt;- top_10_doctors |&gt;\n  pull(covered_recipient_npi)\n\nWe also want a vector of doctor names associated with each of these IDs, but remember that there can be multiple names for a single doctor in this dataset. With this in mind, we are going to create a vector of the first listed name for a given covered_recipient_npi in the dataset. Taking the first listed name as the doctor’s name is an imperfect solution. The first listed name could be a misspelling. It could be a doctor’s maiden name that they have since changed. This is a temporary solution, and we would want to confirm that we have the correct name for each doctor before publishing any of these findings."
  },
  {
    "objectID": "course-materials/labs/lab6/across.html#ex-4-top-10-doctors-names",
    "href": "course-materials/labs/lab6/across.html#ex-4-top-10-doctors-names",
    "title": "SDS192 Lab 6",
    "section": "Ex 4: Top 10 Doctors Names",
    "text": "Ex 4: Top 10 Doctors Names\nCreate a vector containing the names of the doctors associated with the IDs in top_10_doctors_ids. First, define the function get_doctor_name. This function will:\n\nTake a doctor_id as an argument\nFilter open_payments_cleaned to that ID\nSummarize the first() covered_recipient_full_name listed for that ID\npull() the name value\n\nOnce this function has been defined, select the appropriate map() function to iterate top_10_doctors_ids through get_doctor_name and store the resulting character vector in top_10_doctors_names.\n\nget_doctor_name &lt;- function(doctor_id) {\n  open_payments_cleaned |&gt;\n    filter(covered_recipient_npi == {{doctor_id}})|&gt;\n    first()|&gt;\n    pull(covered_recipient_full_name)\n    \n}\n\n# Iterate the top_10_doctors_ids vector through get_doctor_name and store the results in a character vector\ntop_10_doctors_names &lt;-\n  map_chr(\n    .x = top_10_doctors_ids,\n    .f = get_doctor_name\n  )\n\nNow that we have the vectors we want to iterate over, we are ready to start defining our functions."
  },
  {
    "objectID": "course-materials/labs/lab6/across.html#ex-5-what-kind-of-payments-did-ma-based-doctors-receive-in-2021",
    "href": "course-materials/labs/lab6/across.html#ex-5-what-kind-of-payments-did-ma-based-doctors-receive-in-2021",
    "title": "SDS192 Lab 6",
    "section": "Ex 5: What Kind of Payments did MA-based Doctors Receive in 2021?",
    "text": "Ex 5: What Kind of Payments did MA-based Doctors Receive in 2021?\nTo get started, let’s define a function that filters open_payments_cleaned to a given doctor ID, and then calculates how much of each kind of payment has been paid to that doctor. Here is an example of what that data wrangling code would look like for a specific covered_recipient_npi:\n\nopen_payments_cleaned |&gt;\n  filter(covered_recipient_npi == 1194763482) |&gt;\n  group_by(nature_of_payment_or_transfer_of_value) |&gt;\n  summarize(num_payments = \n              sum(number_of_payments_included_in_total_amount),\n            total_payments = sum(total_amount_of_payment_usdollars))\n\n# A tibble: 2 × 3\n  nature_of_payment_or_transfer_of_value num_payments total_payments\n  &lt;chr&gt;                                         &lt;dbl&gt;          &lt;dbl&gt;\n1 Consulting Fee                                    4          5428.\n2 Royalty or License                                2      18750000 \n\n\n\nWrap the above code in a function named calculate_payment_type_amts. Rather than filtering to 1194763482, filter based on the value passed to an argument named doctor_id\nThen, use the map() function to apply calculate_payment_type_amts to each element in the top_10_doctors_ids vector. Running this code should return a list of 10 data frames\nFinally, pipe in set_names(top_10_doctors_names) to set the names for each data frame in the list to the doctor’s name\n\n\n# Write calculate_payment_type_amts function here\ncalculate_payment_type_amts &lt;- function(doctor_id){\n\nopen_payments_cleaned |&gt;\n  filter(covered_recipient_npi == {{doctor_id}}) |&gt;\n  group_by(nature_of_payment_or_transfer_of_value) |&gt;\n  summarize(num_payments = \n              sum(number_of_payments_included_in_total_amount),\n            total_payments = sum(total_amount_of_payment_usdollars))\n}\n\n# Iterate calculate_payment_type_amts over top_10_doctors_ids and set names to top_10_doctors_names\ndoctor_list &lt;- map(\n  .x = top_10_doctors_ids,\n  .f = calculate_payment_type_amts\n) \ndoctor_list&lt;- doctor_list |&gt; set_names(top_10_doctors_names)"
  },
  {
    "objectID": "course-materials/labs/lab6/across.html#ex-6-when-were-payments-made-to-each-of-these-doctors-in-2021",
    "href": "course-materials/labs/lab6/across.html#ex-6-when-were-payments-made-to-each-of-these-doctors-in-2021",
    "title": "SDS192 Lab 6",
    "section": "Ex 6: When were Payments Made to Each of These Doctors in 2021?",
    "text": "Ex 6: When were Payments Made to Each of These Doctors in 2021?\nHere’s an example of a plot we could create to answer this question for one doctor.\n\nopen_payments_cleaned |&gt;\n    filter(covered_recipient_npi == 1194763482) |&gt;\n    ggplot(aes(x = day(date_of_payment), \n               y = \"\", \n               fill = total_amount_of_payment_usdollars)) +\n    geom_jitter(pch = 21, size = 2, color = \"black\") +\n    theme_minimal() +\n    labs(title = \"David Friedman\", \n         y = \"\", \n         x = \"Day\",\n         fill = \"Payment Amount\") +\n    scale_y_discrete(limits = rev) +\n    scale_fill_distiller(palette = \"BuPu\", direction = 1, labels = scales::comma) +\n    facet_wrap(~month(date_of_payment, label = TRUE), nrow = 4) \n\n\n\n\nWrite a function named payments_calendar. The function should:\n\nTake a doctor_id and doctor_name as arguments\nFilter open_payments_cleaned to the doctor’s ID\nCreate payment calendar plot modeled after the one above\nSet the title of the plot to the doctor’s name\n\nAfter you’ve written this function, use the map2() function to apply payments_calendar to each element in the top_10_doctors_ids vector and top_10_doctors_names vector.\n\n# Write payments_calendar function here\npayments_calendar &lt;- function(doctor_id , doctor_name){\n  open_payments_cleaned |&gt;\n    filter(covered_recipient_npi == {{doctor_id}}) |&gt;\n    ggplot(aes(x = day(date_of_payment), \n               y = \"\", \n               fill = total_amount_of_payment_usdollars)) +\n    geom_jitter(pch = 21, size = 2, color = \"black\") +\n    theme_minimal() +\n    labs(title = doctor_name, \n         y = \"\", \n         x = \"Day\",\n         fill = \"Payment Amount\") +\n    scale_y_discrete(limits = rev) +\n    scale_fill_distiller(palette = \"BuPu\", direction = 1, labels = scales::comma) +\n    facet_wrap(~month(date_of_payment, label = TRUE), nrow = 4) \n}\n# Iterate payments_calendar over top_10_doctors_ids and top_10_doctors_ids to create 10 plots\n\nmap2(\n  .x = top_10_doctors_ids,\n  .y = top_10_doctors_names,\n  .f = payments_calendar\n)\n\n[[1]]\n\n\n\n\n\n\n[[2]]\n\n\n\n\n\n\n[[3]]\n\n\n\n\n\n\n[[4]]\n\n\n\n\n\n\n[[5]]\n\n\n\n\n\n\n[[6]]\n\n\n\n\n\n\n[[7]]\n\n\n\n\n\n\n[[8]]\n\n\n\n\n\n\n[[9]]\n\n\n\n\n\n\n[[10]]"
  },
  {
    "objectID": "course-materials/labs/lab6/across.html#ex-7-which-manufacturers-paid-ma-based-doctors-in-2021-and-through-what-forms-of-payment",
    "href": "course-materials/labs/lab6/across.html#ex-7-which-manufacturers-paid-ma-based-doctors-in-2021-and-through-what-forms-of-payment",
    "title": "SDS192 Lab 6",
    "section": "Ex 7: Which Manufacturers Paid MA-based Doctors in 2021, and through What Forms of Payment?",
    "text": "Ex 7: Which Manufacturers Paid MA-based Doctors in 2021, and through What Forms of Payment?\nFinally, let’s define a function that filters open_payments_cleaned to a given doctor ID and determines how much the doctor received in compensation from different manufacturers, along with the forms of payment from each manufacturer. To do so, we will need to aggregate the data by covered_recipient_npi, applicable_manufacturer_or_applicable_gpo_making_payment_name, and form_of_payment_or_transfer_of_value and calculate the total payments associated with each grouping.\nWrite a function named calculate_manufacturer_payments. The function should:\n\nTake a doctor_id as an argument\nFilter open_payments_cleaned to that ID\nAggregate the filtered data by covered_recipient_npi, applicable_manufacturer_or_applicable_gpo_making_payment_name, and form_of_payment_or_transfer_of_value\nCalculate the total amount of payments for each grouping\nSort the resulting data frame in descending order by the total amount of payments\n\nAfter you’ve written this function, use the map_df() function to apply calculate_manufacturer_payments to each element in the top_10_doctors_ids vector. Note how this returns one data frame rather than a list of 10 data frames.\nPlot your resulting data frame as a column plot, attempting (to the best of your ability) to match the formatting of the plot below.\n\n# Write calculate_manufacturer_payments function here\n\ncalculate_manufacturer_payments &lt;- function(doctor_id){\n  open_payments_cleaned |&gt;\n  filter(covered_recipient_npi == {{doctor_id}})|&gt;\n  group_by(\n    covered_recipient_npi,\n    applicable_manufacturer_or_applicable_gpo_making_payment_name,\n    form_of_payment_or_transfer_of_value)|&gt;\n  reframe(total = sum(total_amount_of_payment_usdollars))\n}\n\n\n# Iterate calculate_manufacturer_payments over top_10_doctors_ids here\n\ndf&lt;- map_df(\n  .x = top_10_doctors_ids,\n  .f = calculate_manufacturer_payments\n)\n\n# Plot resulting data frame here\ndf |&gt;\n  ggplot(aes(\n    x = applicable_manufacturer_or_applicable_gpo_making_payment_name, \n    y = total,\n    fill = form_of_payment_or_transfer_of_value)\n    ) +\n  geom_col()+\n  facet_wrap(facets = ~covered_recipient_npi ,ncol = 2, scales = \"free\")+\n  coord_flip()+\n  theme_minimal()+\n  theme(title = element_text(size = 5),\n        axis.title = element_text(size = 4),\n        axis.text = element_text(size = 2),\n        strip.text = element_text(size = 4),\n        legend.title = element_text(size = 4),\n        legend.text = element_text(size = 4)\n        ) +\n  labs(title=\"Total Amount of Medical Drug/Device Payments to 10 MA-based Doctors,2021\", \n         x=\"Name of Manufacturer\",\n         y=\"Total Amount of Payments ($)\")\n\n\n\n  scale_y_continuous(labels = scales::comma)\n\n&lt;ScaleContinuousPosition&gt;\n Range:  \n Limits:    0 --    1\n\ndf\n\n# A tibble: 39 × 4\n   covered_recipient_npi applicable_manufacturer…¹ form_of_payment_or_t…²  total\n                   &lt;dbl&gt; &lt;chr&gt;                     &lt;chr&gt;                   &lt;dbl&gt;\n 1            1194763482 Vertex Pharmaceuticals I… Cash or cash equivale… 1.88e7\n 2            1720096738 Vertex Pharmaceuticals I… Cash or cash equivale… 1.88e7\n 3            1073561973 Smith+Nephew, Inc.        Cash or cash equivale… 2.11e6\n 4            1073561973 Smith+Nephew, Inc.        In-kind items and ser… 1.07e2\n 5            1073561973 Synthes GmbH              Cash or cash equivale… 2.5 e2\n 6            1699732065 DePuy Synthes Products, … Cash or cash equivale… 1.87e6\n 7            1952351488 E.R. Squibb & Sons, L.L.… Stock                  7.91e5\n 8            1952351488 GlaxoSmithKline, LLC.     Cash or cash equivale… 1.81e5\n 9            1194860205 Henry Schein, Inc.        In-kind items and ser… 2.88e2\n10            1194860205 Peter Brasseler Holdings… Cash or cash equivale… 9.71e5\n# ℹ 29 more rows\n# ℹ abbreviated names:\n#   ¹​applicable_manufacturer_or_applicable_gpo_making_payment_name,\n#   ²​form_of_payment_or_transfer_of_value"
  },
  {
    "objectID": "course-materials/labs/lab6/across.html#ex-8-weekly-reflections",
    "href": "course-materials/labs/lab6/across.html#ex-8-weekly-reflections",
    "title": "SDS192 Lab 6",
    "section": "Ex 8: Weekly Reflections",
    "text": "Ex 8: Weekly Reflections\nFill out this week’s reflections Google form to receive credit."
  },
  {
    "objectID": "course-materials/in-class-activies/day_25solutions_function_writing.html",
    "href": "course-materials/in-class-activies/day_25solutions_function_writing.html",
    "title": "Write Functions",
    "section": "",
    "text": "This in class activity was"
  },
  {
    "objectID": "course-materials/in-class-activies/day_25solutions_function_writing.html#exercise-1",
    "href": "course-materials/in-class-activies/day_25solutions_function_writing.html#exercise-1",
    "title": "Write Functions",
    "section": "Exercise 1",
    "text": "Exercise 1\nWrite a function called count_name that, when given a name (e.g.,Angelica, Ezekiel, or Riley) as an argument, returns the total number of births by year from the babynames data frame in the babynames package that match that name.\n\n# Write your code below\ncount_name &lt;- function(data = babynames , nombre = \"Nicholas\"){\n  if(is.element(nombre, babynames$name)) {\n    data |&gt;\n    filter(name == nombre) |&gt;\n    group_by(name,year) |&gt;\n    reframe(year= year, n = sum(n)) \n      \n  }\n  else{\n    stop(\"Name not found\")\n  }\n}"
  },
  {
    "objectID": "course-materials/in-class-activies/day_25solutions_function_writing.html#bonus",
    "href": "course-materials/in-class-activies/day_25solutions_function_writing.html#bonus",
    "title": "Write Functions",
    "section": "Bonus!",
    "text": "Bonus!\nThe count_name function should return one row per year that matches (and generate an error message if there are no matches). Run the function once with the argument Ezekiel and once with Ezze.\n\n# Paste the code from Exercise 1 below and adjust it\ncount_name(data=babynames, nombre = \"Ezekiel\")\n\n# A tibble: 141 × 3\n   name     year     n\n   &lt;chr&gt;   &lt;dbl&gt; &lt;int&gt;\n 1 Ezekiel  1880    16\n 2 Ezekiel  1881    22\n 3 Ezekiel  1882    11\n 4 Ezekiel  1883    14\n 5 Ezekiel  1884    13\n 6 Ezekiel  1885    10\n 7 Ezekiel  1886    17\n 8 Ezekiel  1887    11\n 9 Ezekiel  1888    16\n10 Ezekiel  1889    14\n# ℹ 131 more rows\n\n#count_name(\"Ezze\")"
  },
  {
    "objectID": "course-materials/in-class-activies/day_25solutions_function_writing.html#exercise-2",
    "href": "course-materials/in-class-activies/day_25solutions_function_writing.html#exercise-2",
    "title": "Write Functions",
    "section": "Exercise 2",
    "text": "Exercise 2\nWrite a function called grab_name that, when given a name and a year as an argument, returns the rows from the babynames data frame in the babynames package that match that name for that year (and returns an error if that name and year combination does not match any rows). Run the function once with the arguments Ezekiel and 1883 and once with Ezze and 1883.\nChallenge: Add an else if after your if and before your else to catch an error if people choose a year less than 1880 (outside of the range of our data).\n\n# Write your code below\n\nlibrary(tidyverse)\nlibrary(babynames)\n\ngrab_name &lt;- function(data = babynames, nombre ,ano ){\n\n  if(is.element(nombre,babynames$name))  {\n    data |&gt;\n    filter(name == nombre & year == ano) |&gt;\n    pull(name,year)\n  }\n  else if(ano &lt; 1880){\n    stop(\"Choose a year after 1880\")\n  }\n  else{\n    stop(\"Name and year not found\")\n  }\n}\ngrab_name( nombre = \"Samantha\", ano = 1950)\n\n      1950 \n\"Samantha\""
  },
  {
    "objectID": "course-materials/in-class-activies/day_25solutions_function_writing.html#exercise-3",
    "href": "course-materials/in-class-activies/day_25solutions_function_writing.html#exercise-3",
    "title": "Write Functions",
    "section": "Exercise 3",
    "text": "Exercise 3\nWrite a function called count_name_graph() that will use the function countname() to make a line graph that plots the year and the number of babies in a given year. The graph’s title should be “the”Babies Named (name of baby)” . The paste() function in r will help with your title, use it to put two strings together. Label your x and y axes.\n\n# Write your code below\ncount_name_graph &lt;- function(data, nombre = \"Nicholas\"){\n  count_name(data, nombre )|&gt;\n    ggplot(aes(x=year, y=n))+\n    geom_line()+\n    labs(title = paste(\"Babies named\", nombre))\n}\ncount_name_graph(data=babynames, nombre = \"Nicholas\")"
  },
  {
    "objectID": "course-materials/in-class-activies/day_25solutions_function_writing.html#exercise-4",
    "href": "course-materials/in-class-activies/day_25solutions_function_writing.html#exercise-4",
    "title": "Write Functions",
    "section": "Exercise 4",
    "text": "Exercise 4\nWrite a function called summary_prop that will take a data frame as an argument, filter to a condition, and compute the proportion of that condition.\nRun the function with the arguments congress_age and age &gt;= 25 & age &lt;= 55 .\nYou can use your function on count_name(\"Ezekiel\"), n&gt;100. (Note: You probably used summarize() for the code for exercise 1, that sometimes returns grouped data. This code will work better if you add a pipe to an ungroup(). Alternatively you can just use reframe() instead of summarize()).\n\n# Write your code below\nsummary_prop &lt;- function(data, condition){\n  data |&gt; \n    filter( {{condition}} )|&gt;\n    summarise(\n      number_with_condition = n(),\n      prop_w_condition = number_with_condition/nrow(data)\n    )\n}\n  \nsummary_prop(data=congress_age, condition = age &gt;= 25 & age &lt;= 55)\n\n# A tibble: 1 × 2\n  number_with_condition prop_w_condition\n                  &lt;int&gt;            &lt;dbl&gt;\n1                 10657            0.572\n\nsummary_prop(data=count_name(data = babynames, nombre = \"Ezekiel\"), condition = n&gt;100)\n\n# A tibble: 1 × 2\n  number_with_condition prop_w_condition\n                  &lt;int&gt;            &lt;dbl&gt;\n1                    44            0.312"
  },
  {
    "objectID": "course-materials/lectures/Day_26_across_maps.html#across-and-map",
    "href": "course-materials/lectures/Day_26_across_maps.html#across-and-map",
    "title": "iteration",
    "section": "",
    "text": "These functions allow us to preform the same operation across multiple rows.\nmap() comes from the purr package.\nacross() comes from the dplyr package."
  },
  {
    "objectID": "course-materials/lectures/Day_26_across_maps.html#example-iris",
    "href": "course-materials/lectures/Day_26_across_maps.html#example-iris",
    "title": "iteration",
    "section": "Example: iris",
    "text": "Example: iris\n\nhead(iris)\n\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n1          5.1         3.5          1.4         0.2  setosa\n2          4.9         3.0          1.4         0.2  setosa\n3          4.7         3.2          1.3         0.2  setosa\n4          4.6         3.1          1.5         0.2  setosa\n5          5.0         3.6          1.4         0.2  setosa\n6          5.4         3.9          1.7         0.4  setosa"
  },
  {
    "objectID": "course-materials/lectures/Day_26_across_maps.html#average",
    "href": "course-materials/lectures/Day_26_across_maps.html#average",
    "title": "iteration",
    "section": "Average",
    "text": "Average\nLet’s find the average of each column that ends with .Length by species.\n\niris %&gt;%\n  group_by(Species) %&gt;%\n  summarise(\n    across(.cols = ends_with(\"Length\"), \n           .fns = list(mean = mean)))\n\n# A tibble: 3 × 3\n  Species    Sepal.Length_mean Petal.Length_mean\n  &lt;fct&gt;                  &lt;dbl&gt;             &lt;dbl&gt;\n1 setosa                  5.01              1.46\n2 versicolor              5.94              4.26\n3 virginica               6.59              5.55"
  },
  {
    "objectID": "course-materials/lectures/Day_26_across_maps.html#rounding",
    "href": "course-materials/lectures/Day_26_across_maps.html#rounding",
    "title": "iteration",
    "section": "Rounding",
    "text": "Rounding\n\niris %&gt;%\n  group_by(Species) %&gt;%\n  reframe(across(\n    .cols = starts_with(\"Sepal\"), \n    .fns = ~ round(. , digits = 2)))\n\n# A tibble: 150 × 3\n   Species Sepal.Length Sepal.Width\n   &lt;fct&gt;          &lt;dbl&gt;       &lt;dbl&gt;\n 1 setosa           5.1         3.5\n 2 setosa           4.9         3  \n 3 setosa           4.7         3.2\n 4 setosa           4.6         3.1\n 5 setosa           5           3.6\n 6 setosa           5.4         3.9\n 7 setosa           4.6         3.4\n 8 setosa           5           3.4\n 9 setosa           4.4         2.9\n10 setosa           4.9         3.1\n# ℹ 140 more rows"
  },
  {
    "objectID": "course-materials/lectures/Day_26_across_maps.html#rounding-1",
    "href": "course-materials/lectures/Day_26_across_maps.html#rounding-1",
    "title": "iteration",
    "section": "Rounding",
    "text": "Rounding\n\niris %>%\n  group_by(Species) %>%\n  reframe(across(\n    .cols = starts_with(\"Sepal\"), \n    .fns = ~ round(. , digits = 2)))\n\n# A tibble: 150 × 3\n   Species Sepal.Length Sepal.Width\n   <fct>          <dbl>       <dbl>\n 1 setosa           5.1         3.5\n 2 setosa           4.9         3  \n 3 setosa           4.7         3.2\n 4 setosa           4.6         3.1\n 5 setosa           5           3.6\n 6 setosa           5.4         3.9\n 7 setosa           4.6         3.4\n 8 setosa           5           3.4\n 9 setosa           4.4         2.9\n10 setosa           4.9         3.1\n# ℹ 140 more rows"
  },
  {
    "objectID": "course-materials/lectures/Day_26_across_maps.html#map-is-similar-to-across",
    "href": "course-materials/lectures/Day_26_across_maps.html#map-is-similar-to-across",
    "title": "iteration",
    "section": "map() is similar to across()",
    "text": "map() is similar to across()\nIt performs some operation on a data frame, vector or list.\n\niris |&gt;\n  map(.f = mean)\n\nWarning in mean.default(.x[[i]], ...): argument is not numeric or logical:\nreturning NA\n\n\n$Sepal.Length\n[1] 5.843333\n\n$Sepal.Width\n[1] 3.057333\n\n$Petal.Length\n[1] 3.758\n\n$Petal.Width\n[1] 1.199333\n\n$Species\n[1] NA"
  },
  {
    "objectID": "course-materials/lectures/Day_26_across_maps.html#different-maps",
    "href": "course-materials/lectures/Day_26_across_maps.html#different-maps",
    "title": "iteration",
    "section": "Different maps()",
    "text": "Different maps()\nmap() returns a list.\nmap_dfc() returns a dataframe with columns\nmap_dfr() returns a dataframe with rows."
  },
  {
    "objectID": "course-materials/lectures/Day_26_across_maps.html#map_dfc",
    "href": "course-materials/lectures/Day_26_across_maps.html#map_dfc",
    "title": "iteration",
    "section": "map_dfc()",
    "text": "map_dfc()\n\niris |&gt;\n  map_dfc(.f = mean)\n\nWarning in mean.default(.x[[i]], ...): argument is not numeric or logical:\nreturning NA\n\n\n# A tibble: 1 × 5\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n         &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;       &lt;dbl&gt;   &lt;dbl&gt;\n1         5.84        3.06         3.76        1.20      NA"
  },
  {
    "objectID": "course-materials/lectures/Day_26_across_maps.html#rounding-with-across",
    "href": "course-materials/lectures/Day_26_across_maps.html#rounding-with-across",
    "title": "iteration",
    "section": "Rounding with across()",
    "text": "Rounding with across()\n\niris %&gt;%\n  group_by(Species) %&gt;%\n  summarise(across(\n    .cols = Sepal.Length:Petal.Width, \n    .fns = round))\n\nWarning: Returning more (or less) than 1 row per `summarise()` group was deprecated in\ndplyr 1.1.0.\nℹ Please use `reframe()` instead.\nℹ When switching from `summarise()` to `reframe()`, remember that `reframe()`\n  always returns an ungrouped data frame and adjust accordingly.\n\n\n`summarise()` has grouped output by 'Species'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 150 × 5\n# Groups:   Species [3]\n   Species Sepal.Length Sepal.Width Petal.Length Petal.Width\n   &lt;fct&gt;          &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;       &lt;dbl&gt;\n 1 setosa             5           4            1           0\n 2 setosa             5           3            1           0\n 3 setosa             5           3            1           0\n 4 setosa             5           3            2           0\n 5 setosa             5           4            1           0\n 6 setosa             5           4            2           0\n 7 setosa             5           3            1           0\n 8 setosa             5           3            2           0\n 9 setosa             4           3            1           0\n10 setosa             5           3            2           0\n# ℹ 140 more rows"
  },
  {
    "objectID": "course-materials/lectures/Day_26_across_maps.html#rounding-without-across",
    "href": "course-materials/lectures/Day_26_across_maps.html#rounding-without-across",
    "title": "iteration",
    "section": "Rounding without across()",
    "text": "Rounding without across()\n\niris %&gt;%\n  group_by(Species) %&gt;%\n  summarise(Sepal.Length = round(Sepal.Length),\n            Sepal.Width = round(Sepal.Width),\n            Petal.Length = round(Petal.Length),\n            Petal.Width = round(Petal.Width))\n\nWarning: Returning more (or less) than 1 row per `summarise()` group was deprecated in\ndplyr 1.1.0.\nℹ Please use `reframe()` instead.\nℹ When switching from `summarise()` to `reframe()`, remember that `reframe()`\n  always returns an ungrouped data frame and adjust accordingly.\n\n\n`summarise()` has grouped output by 'Species'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 150 × 5\n# Groups:   Species [3]\n   Species Sepal.Length Sepal.Width Petal.Length Petal.Width\n   &lt;fct&gt;          &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;       &lt;dbl&gt;\n 1 setosa             5           4            1           0\n 2 setosa             5           3            1           0\n 3 setosa             5           3            1           0\n 4 setosa             5           3            2           0\n 5 setosa             5           4            1           0\n 6 setosa             5           4            2           0\n 7 setosa             5           3            1           0\n 8 setosa             5           3            2           0\n 9 setosa             4           3            1           0\n10 setosa             5           3            2           0\n# ℹ 140 more rows"
  },
  {
    "objectID": "readme.html",
    "href": "readme.html",
    "title": "SDS 192 Fall '23",
    "section": "",
    "text": "Source code to generate the course webpage for Smith College: Introduction to Data Science https://nics-github.github.io/SDS192/. Most of the content is in either:\n\n_quarto.yml: Set theme of webpage along with links in navigational bar.\nindex.qmd: A single Moodle-style page that lists all announcements and lectures notes in reverse-chronological order.\nPS.qmd: All problem sets/homeworks.\nprojects.qmd: Details on the mini-projects and term project.\nsyllabus.qmd: Course info/description, topics, materials, evaluation, and expectations.\n\n\n\nThis webpage is built/compiled using R Markdown Websites. To compile this webpage for yourself, do the following:\n\nGet the contents of this directory/repository:\n\nIf you are not familiar with GitHub, click the green “Clone or download” button on the top-right -> Download ZIP -> Unzip SDS192-master.zip.\nIf you are familiar with GitHub, clone this repository.\n\nDouble-click the SDS192.Rproj to open RStudio.\nIf you haven’t already, install the following R packages:\n\nrmarkdown and devtools\nAt the top of index.Rmd: all CRAN R packages listed .\nAt the top of index.Rmd: the emo and patchwork packages must be installed from GitHub using the devtools::install_github() function.\n\nGo to the “Build” pane of RStudio -> More -> Configure Build Tools… -> Ensure that “Project build tools” is set to “Webpage”.\nClick “Build Website”.\nThe website will display in the Viewer pane. The resulting index.html file and all other files for the webpage will be saved in the docs/ folder.\n\n\n\n\nTo publish/deploy this webpage and make it viewable on the web, you need to either:\n\nCopy the contents of the docs/ folder to your personal webpage or whatever domain hosting service you use.\nUse GitHub pages as I do. RStudio’s R Markdown Websites page gives instructions on how.\n\n\n\n\nThe format for this site was borrowed from Albert Kim’s SDS 192 course\nIf not created by me or referred to in some other way the activities and projects for this course are from:\n\nThe above mentioned website\nData Science in a box.\nBen Baumer’s SDS 192 course page"
  },
  {
    "objectID": "course-materials/in-class-activies/day_25solutions_function_writing.html#exercise-1-masked-data",
    "href": "course-materials/in-class-activies/day_25solutions_function_writing.html#exercise-1-masked-data",
    "title": "Lec 20: In-class Exercise: Write Functions",
    "section": "Exercise 1 masked data",
    "text": "Exercise 1 masked data\nWrite a function called count_name that, when given a name (e.g.,Angelica, Ezekiel, or Riley) as an argument, returns the total number of births by year from the babynames data frame in the babynames package that match that name.\n\n# Write your code below\ncount_name &lt;- function(data , nombre = \"Nicholas\"){\n  if(is.element(nombre, babynames$name)) {\n    data |&gt;\n      ## Why do I not need to mask {{nombre}}?\n    filter(name == nombre) |&gt;\n    group_by(name,year) |&gt;\n    reframe(year= year, n = sum(n)) \n      \n  }\n  else{\n    stop(\"Name not found\")\n  }\n}"
  },
  {
    "objectID": "course-materials/lectures/maps-ggplot.html",
    "href": "course-materials/lectures/maps-ggplot.html",
    "title": "maps-ggplot",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.3     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(mdsr)\nlibrary(sf)\n\nLinking to GEOS 3.11.0, GDAL 3.5.3, PROJ 9.1.0; sf_use_s2() is TRUE\n\nlibrary(ggspatial)\nlibrary(leaflet)\nlibrary(tidygeocoder)\nlibrary(mapproj)\n\nLoading required package: maps\n\nAttaching package: 'maps'\n\nThe following object is masked from 'package:purrr':\n\n    map\n\nlibrary(maps)\n\nLet’s find the latitude and longitude for a couple of places.\n\naddresses&lt;- tibble(address=c(\"Smith College\", \"2 Tyler Ct, Northampton, MA 01060\", \"Holyoke Community College\")) |&gt;\ngeocode(address, method=\"osm\") |&gt;\n  mutate(name = c(\"Smith College\",\"McConnell Hall\",\"Holyoke Community College\"))\n\nPassing 3 addresses to the Nominatim single address geocoder\n\n\nQuery completed in: 3 seconds\n\naddresses\n\n# A tibble: 3 × 4\n  address                             lat  long name                     \n  &lt;chr&gt;                             &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;                    \n1 Smith College                      42.3 -72.6 Smith College            \n2 2 Tyler Ct, Northampton, MA 01060  42.3 -72.6 McConnell Hall           \n3 Holyoke Community College          42.2 -72.7 Holyoke Community College\n\n\nLet’s plot those with ggplot.\n\nggplot(addresses) +\n  geom_point(aes(long,lat)) \n\n\n\n\nNot very exciting. We’ll add it it in a moment.\nLet’s build a map of Massachusetts with the map_data() function\n\nma_counties &lt;- map_data(\"county\", \"massachusetts\") %&gt;% \n  select( long, lat, group, id = subregion)\n\nhead(ma_counties)\n\n       long      lat group         id\n1 -70.67435 41.73997     1 barnstable\n2 -70.53683 41.79727     1 barnstable\n3 -70.53683 41.79727     1 barnstable\n4 -70.51392 41.78008     1 barnstable\n5 -70.47954 41.75716     1 barnstable\n6 -70.41078 41.73425     1 barnstable\n\n\nNotice there are a lot of points for barnstable. Those are the vertices of a polygon. Let’s draw the polygon with the points.\n\nma_counties |&gt; ggplot(aes(long,lat,group=group))+\n  geom_polygon(fill = \"white\", colour = \"grey50\")+\n  geom_point()  \n\n\n\n  #coord_sf()\n\n\nma_counties |&gt; ggplot(aes(long,lat,group=group))+\n  geom_polygon(fill = \"white\", colour = \"grey50\")+\n  geom_point()+\n  coord_sf()\n\n\n\n\nLet’s grab just Massachusetts cities from the data frame us.cities.\n\nma_cities &lt;- us.cities |&gt;\n  filter(country.etc ==\"MA\") |&gt;\n  select(name, long, lat)\n\nhead(ma_cities)\n\n                name   long   lat\n1         Andover MA -71.14 42.65\n2       Arlington MA -71.16 42.42\n3       Attleboro MA -71.30 41.93\n4 Barnstable Town MA -70.30 41.70\n5         Beverly MA -70.84 42.56\n6       Billerica MA -71.26 42.56\n\n\nExercise: Plot MA cities onto our county map.\n\nma_counties |&gt; ggplot(aes(long,lat))+\n  geom_polygon(fill = \"white\", colour = \"grey50\",aes(group=group)) +\n  #geom_point(data=ma_cities,.......)\n  \n  #This is the default mapping. Think GPS\n coord_sf(default_crs= st_crs(4326) )\n\n\n\n          # This is Mercator\n          # st_crs(3857))\n\nLet’s get some more accurate government data.\nGo here and download some shape files.\nSaving them will be a bit of work. First we need to find those files.\n\nstates &lt;- read_sf(\"\") |&gt;\n  sf::st_transform('+proj=longlat +datum=WGS84')\n\ncounties &lt;- read_sf(\"\") |&gt;\n  st_transform('+proj=longlat +datum=WGS84')"
  },
  {
    "objectID": "course-materials/Final-Project/Project.html",
    "href": "course-materials/Final-Project/Project.html",
    "title": "SDS 192 Fall '23",
    "section": "",
    "text": "As part of the coursework requirement for SDS 220, you will conduct a quantitative analysis on a real data set with the goal of using data analysis to address a research question. Your final product will be a written report describing the motivation for the project, details of the data used in the analysis, and the conclusions drawn from your analysis. The project is an opportunity to integrate what you’ve learned about data wrangling, data visualization, and statistical inference with statistical communication skills.\nThe core project requirements pertain to the statistical analysis you perform, and the narrative structure of your written report. Roughly speaking, your data analysis project will address a question like “How is {Variable X} related to {Variable Y}”. This means that your data set must measure several variables.\nYour analysis must also include at least one hypothesis test that allows you to draw an inferential conclusions about how your outcome variable is related to your explanatory variable(s). For example, you may include a hypothesis test for a difference in means, a hypothesis test for a difference in proportions, or a hypothesis test on the coefficients of a regression model.\nWhen choosing which variables to use in your analysis, it is prudent to keep the hypothesis testing requirement in mind. For example, before choosing a categorical variable with 5 levels as your outcome, and a numeric explanatory variable, ask yourself: Do I know how to conduct a hypothesis test that would answer a research question about how these kinds of variables relate? If not, it is recommended that you choose a different set of variables to analyze.\nYour report should be structured as a narrative document that introduces the topic of your analysis (including your research question(s) and the goals of your data analysis), explains the nature of the data you are analyzing in sufficient detail, explains what analyses are being performed and what can be learned from them, and ends with overall conclusions related to your research question that are supported by your data analysis. Your writing should be supplemented with illustrative figures and tables that help the reader understand how these data help answer the questions of your investigation. Your report should also cite at least one outside source of information (in addition to citing the source of your data), though that source does not necessarily have to be a peer-reviewed `academic’ article."
  },
  {
    "objectID": "course-materials/Final-Project/Project.html#project-overview",
    "href": "course-materials/Final-Project/Project.html#project-overview",
    "title": "SDS 192 Fall '23",
    "section": "",
    "text": "As part of the coursework requirement for SDS 220, you will conduct a quantitative analysis on a real data set with the goal of using data analysis to address a research question. Your final product will be a written report describing the motivation for the project, details of the data used in the analysis, and the conclusions drawn from your analysis. The project is an opportunity to integrate what you’ve learned about data wrangling, data visualization, and statistical inference with statistical communication skills.\nThe core project requirements pertain to the statistical analysis you perform, and the narrative structure of your written report. Roughly speaking, your data analysis project will address a question like “How is {Variable X} related to {Variable Y}”. This means that your data set must measure several variables.\nYour analysis must also include at least one hypothesis test that allows you to draw an inferential conclusions about how your outcome variable is related to your explanatory variable(s). For example, you may include a hypothesis test for a difference in means, a hypothesis test for a difference in proportions, or a hypothesis test on the coefficients of a regression model.\nWhen choosing which variables to use in your analysis, it is prudent to keep the hypothesis testing requirement in mind. For example, before choosing a categorical variable with 5 levels as your outcome, and a numeric explanatory variable, ask yourself: Do I know how to conduct a hypothesis test that would answer a research question about how these kinds of variables relate? If not, it is recommended that you choose a different set of variables to analyze.\nYour report should be structured as a narrative document that introduces the topic of your analysis (including your research question(s) and the goals of your data analysis), explains the nature of the data you are analyzing in sufficient detail, explains what analyses are being performed and what can be learned from them, and ends with overall conclusions related to your research question that are supported by your data analysis. Your writing should be supplemented with illustrative figures and tables that help the reader understand how these data help answer the questions of your investigation. Your report should also cite at least one outside source of information (in addition to citing the source of your data), though that source does not necessarily have to be a peer-reviewed `academic’ article."
  },
  {
    "objectID": "course-materials/Final-Project/Project.html#stages-and-timeline",
    "href": "course-materials/Final-Project/Project.html#stages-and-timeline",
    "title": "SDS 192 Fall '23",
    "section": "Stages and Timeline",
    "text": "Stages and Timeline\nYou will complete your project several stages outlined below. More details about what is required to complete each stage is described in the subsequent sections.\n\nFriday, November 17 - Group formation and Data Set Selection (2 points)\n\n\n\n\n\n\nData Analysis Plan \nProject Presentation\nSaturday, December 20 - Written Report\nSaturday, December 20 - Reflection"
  },
  {
    "objectID": "course-materials/Final-Project/Project.html#group-formation-and-data-set-selection",
    "href": "course-materials/Final-Project/Project.html#group-formation-and-data-set-selection",
    "title": "SDS 192 Fall '23",
    "section": "Group formation and Data Set Selection",
    "text": "Group formation and Data Set Selection\nYou will work in pairs to complete this project, and you will choose your partner yourself. If you do not have a good idea who you want to work with, I encourage you to solicit potential project partners in the course slack.\nInforming the instructor who you are working with is considered the first checkpoint of the group project assignment. You are expected to fill out the provided form before the deadline posted. In the event you are unable to join a group by the deadline, or do not inform the instructor, you will be assigned to a group by the instructor.\nOnce you have formed your group, the next step in the project is chosing your data set and planning your analysis. You are free to use any data set the meets the below requirements:\n\nYou may not use any variable representing temporal measurement (months, days, years, etc.) as explanatory variable\nYou may not use proportions/percentages as your outcome variable\nThe data set must be in a “tidy” data format to start with\nThere must be at least 10 observations per level in all categorical variables\nYou may not use any data sets used in this class, the Into to Modern Statistics [IMS] book, or any data used as part of example demonstrations.\n\nTo simplify the process of choosing a data set, a curated list of data sets that are appropriate for this project is provided HERE. Additionally, if you wish to use a data set not on the curated list, you must get approval.\nYou will inform the instructor who you are working with, and your chosen data set using the form provided HERE (only one group member needs to fill out the form). This form is graded on completion provided it is submitted by the due date."
  },
  {
    "objectID": "course-materials/Final-Project/Project.html#data-analysis-plan",
    "href": "course-materials/Final-Project/Project.html#data-analysis-plan",
    "title": "SDS 192 Fall '23",
    "section": "Data Analysis Plan",
    "text": "Data Analysis Plan\nOnce you’ve chosen a data set, you must form a research question, and plan an analysis suitable to address your question. One member of your group must fill out the Data Analysis Pre-Registration form. This form to submit this is HERE, and will ask you:\n\nWhat variables you plan to analyze\nWhat research question you have\nWhat hypothesis you have about your variables\nHow you plan to test your hypothesis\nHow will you divide the work\n\nCompleting the Data Analysis Pre-Registration form is considered the second checkpoint of the group project assignment. You are expected to fill out the Data Analysis Pre-Registration form before the deadline posted. If no one from your group fills out the Data Analysis Pre-Registration form by the posted deadline, your group will be assigned a data set by the instructor, and a receive a 0 for this portion of the grade. \nNote, your plan can have errors, this is chance to have feedback. We are looking to see if you have thought carefully about a plan. You are also allowed to make minor changes your plan after the form has been submitted."
  },
  {
    "objectID": "course-materials/Final-Project/Project.html#data-analysis-report",
    "href": "course-materials/Final-Project/Project.html#data-analysis-report",
    "title": "SDS 192 Fall '23",
    "section": "Data Analysis Report",
    "text": "Data Analysis Report\nIn this final phase, you will execute the project by writing a technical report that introduces your topics, describes your data and analysis, and explains the conclusions that are supported by your analysis. Many of the key features of this report have already been described in the Core Project Requirements section. In general, your report should follow this basic format:\n\nIntroduction: an overview of your project. In a few paragraphs, you should explain clearly and precisely what your research question is, why it is interesting, and what contribution you have made towards answering that question. You should give an overview of the specifics of your model, but not the full details. Most readers never make it past the introduction, so this is your chance to hook the reader, and is in many ways the most important part of the paper!\nData: a brief description of your data set. This section should introduce the reader to the data by answering questions such as: what variables are included? Where did they come from? What are units of measurement? What is the population that was sampled? How was the sample collected? This section should also acquaint the reader with your data set through the use of univariate and multivariate visualizations, and univariate and multivariate summaries.\nResults: A hypothesis test set up to address your research questions(s). You should interpret the results in the context of the data explain their relevance. If you are using a regression model in your analysis, each of it’s coefficients should be clearly explained. You should include negative results, but be careful about how you interpret them. For example, you may want to say something along the lines of: ‘we found no evidence that explanatory variable x is associated with response variable y,’ or ‘explanatory variable x did not provide any additional explanatory power above what was already conveyed by explanatory variable z’. On other hand, you probably shouldn’t claim: ‘there is no relationship between x and y’.\nDicussion/Conclusion: a summary of your findings and a discussion of their limitations. Be sure to remind the reader of the question that you originally set out to answer, and summarize your answer to the question. Your discussion should also protect yourself against misinterpretation by being clear about what is not implied by your research. Finally, you should also discuss the limitations of your analysis and/or data, and how it could be augmented or improved with future research. This `future questions’ portion of the discussion should include a brief exploratory analysis showing how your project could be extended to include additional explanatory variables in the future.\nAppendix (Potentially Optional): If you have any supplemental analyses that would be of interest (e.g., examining the assumptions of your two-sample t-tets), you may wish to place those analyses in an appendix at the end of your report.\nBibliography: Your report should contain at least two references (one of those references must be the source of your data). You can use any reasonable citation style (e.g., APA or MLA format), but regardless of style, your bibliography should clearly identify the primary source you are referencing.\n\nTo complete the project, your group should submit\n\nYour written report as either a PDF document,\nThe .qmd or .Rmd file that, when rendered, creates the self-contained PDF document for the report.\nYour bibtex references file (and your citation style file, if any citation style file was used)\n\nThere is no limit to the length of the technical report, but it should not be longer than it needs to be; you should strive to express your ideas concisely and precisely in all situations. Even though you are expected to write your technical report as an Rmarkdown or Quarto document, the PDF file you submit should not display any R code, warnings, or messages. Your technical report should also be well formatted and well organized (e.g., using properly formatted headers to divide sections, using LaTeX markup for mathematical symbols where needed, tables should have bolded column and row labels, etc.)."
  },
  {
    "objectID": "course-materials/Final-Project/Project.html#guidelines-for-successful-statistical-writing",
    "href": "course-materials/Final-Project/Project.html#guidelines-for-successful-statistical-writing",
    "title": "SDS 192 Fall '23",
    "section": "Guidelines for Successful Statistical Writing",
    "text": "Guidelines for Successful Statistical Writing\nThis document should be written for peer reviewers, who comprehend statistics at least as well as you do. You should aim for a level of complexity that is more statistically sophisticated than an article in the Science section of The New York Times, but less sophisticated than an academic journal. For example, your report will use terms that that you will likely never see in the Times (e.g. a \\(t\\)-statistic), but you should not dwell or expound on technical points with no obvious ramifications for the reader (e.g., explaining that your plots were made using ggplot2, or including the definition of a p-value after reporting the p-value of your test statistic). Your goal for this paper is to convince a statistically-minded reader (e.g. a student in this class, or a student from another school who has taken an introductory statistics class) that you have addressed an interesting research question in a meaningful way. But even a reader with no background in statistics should be able to read your report and get the gist of it.\nA good example of how the writing in this report might differ from the writing you’ve done on a HW assignment or exam is how you describe (or rather, don’t) describe your null and alternative hypotheses. In a HW assignment or exam, you might be asked to explicitly state your null and alternative hypotheses in words and symbols, and included sentences like ‘The null hypothesis is that in the population of all babies, there is no difference in the average birth weight between babies born to smokers babies born to non-smokers’ or equations like \\(\\mu_A – \\mu_B = 0\\). But in a research paper, you would not include such literal descriptions of the null hypothesis; rather, you would explain your research question (‘Does the smoking behavior of pregnant women affect their baby’s birth weight?’) and how you chose to address this research question with data analysis (e.g., a two-sample t-test, using a two-tailed p-value). In other words, you shouldn’t explicitly write the null and alternative hypotheses, but a statistically literate reader should be able to answer the question ‘What are the null and alternative hypotheses being tested?’ based on your writing.\nThis report is not simply a dump of all the figures, tables, and calculations that you made during this project, or a story about all the things you tried out in the beginning of the project but didn’t end up keeping. Rather, the technical report should be focused and concise, and based on the minimal set of R code that is necessary to understand your results and findings in full. If you make a claim about your research question or data, it must be justified by explicit calculation. A knowledgeable reviewer should be able to run each line of code in your .qmd or .Rmd file without modification, and verify every statement that you have made.\nAnd even though your report may be written in a Quarto document, and rendered in RStudio, its primary purpose is to be a narrative report that describes how you addressed your research question, not a computer program or a lab notebook with technical details and no context. You should not present tables, figures, or calculations without a written explanation of the information that is supposed to be conveyed by that table or figure. Keep in mind the distinction between data and information. For example, simply displaying a table with the means and standard deviations of your variables with not explanation is not meaningful. And adding an accompanying sentence that reiterates the content of the table (e.g. ‘the mean of variable x was 34.5 and the standard deviation was 2.8…’) is equally meaningless. What you should strive to do is interpret these values in context (e.g. ‘although variables \\(x_1\\) and \\(x_2\\) have similar means, the variability of \\(x_1\\) is much larger, suggesting…’)."
  },
  {
    "objectID": "course-materials/Final-Project/Project.html#written-report-grading",
    "href": "course-materials/Final-Project/Project.html#written-report-grading",
    "title": "SDS 192 Fall '23",
    "section": "Written Report Grading",
    "text": "Written Report Grading\nBelow is a rough list of features I will be looking for when judging the quality of the final project report. Each section will be graded out of 5 points, for a total of 25 points: (5) Exceptional, (4) very good, (3) satisfactory, (2) below expectations, (1) reasonable attempt.\nIntroduction\n\nIs the topic clearly explained?\nIs the research question / goals for the analysis clearly explained?\nIs there any justification or motivation for this study?\nAre the outcome and explanatory variables of interest clearly identified?\nAre important parts of upcoming analysis and conclusion foreshadowed?\nIs the source of the data clearly explained and cited?\n\nExploratory Data Analysis\n\nAre any important data wrangling steps (e.g., filtering missing values, recoding variables) and any impacts of these steps clearly described?\nIs the number of observations clearly identified?\nAre the distributions of each outcome and explanatory variable visualized and clearly described? Are the distributions summarized with appropriate statistics?\nAre the relationships between variables explored with visualizations? Are these relationships discussed and interpreted in writing?\nDo all figures and tables have captions, and is the content of figures/tables sufficiently unpackage/explained for the reader?\nAre the content of the figures and tables overly redundant (they should not be!)\n\nResults\n\nIs the type of test you are using made clear?\nIs the relationship between the research question and hypothesis test made clear?\nAre the test statistic, p-value, degrees of freedom (t-test only) and alpha level clearly explained?\nAre the results of the test clear?\nAre you including a confidence interval around the statistics relevant for your hypothesis test?\nIs your Null Hypothesis Distribution shown?\nAre your model’s coefficients clearly interpreted, and is the fitted regression equation presented (regression only) ?\nAre your hypothesis test’s assumptions, if any, investigated to make sure they are reasonable assumptions to make? (These assumptions may be assessed in an appendix section)\n\nDiscussion\n\nAre all the conclusions explained in a clear and straightforward manner such a that person without statistical training or domain expertise can understand them?\nAre the results of your analysis clearly tied back to your analysis goals and research questions?\nIs there any discussion of what the results mean (e.g., are the results and conclusion connected back the motivation for your study?)\nAre limitations of your analysis and/or data acknowledged?\nDoes your discussion include a brief exploratory analysis showing how your project could be extended to include additional explanatory variables in the future?\n\nWriting Style\n\nOverall throughout the report, are the ideas expressed precisely and concisely?\nOverall throughout the report, is the writing and exposition in the report geared towards someone with a similar level of statistical training (e.g., the writing doesn’t rely heavily on jargon, but also doesn’t elaborate on minute details that don’t benefit the readers understanding of the research).\nDoes the report include a citaiton for the source of the data, and reference at least one outside source, using approrpriate in-text citations and a formatted bibliography?\nIs the R code hidden from the reader, and is the report free from messages, warning messages, and error messages?\nIs the output from your R code appropriately styled (i.e., are tables formatted as tables?) and is the report free from ‘random’ outputs (e.g., a p-value being printed out in the middle of a paragraph)"
  },
  {
    "objectID": "course-materials/Final-Project/Project.html#reflection",
    "href": "course-materials/Final-Project/Project.html#reflection",
    "title": "SDS 192 Fall '23",
    "section": "Reflection",
    "text": "Reflection\nYou will write a short reflection piece describing what you learned from working on this project and how well you and your group navigated the collaborative learning process.\nDetails coming soon!"
  },
  {
    "objectID": "data_for_mapping.html",
    "href": "data_for_mapping.html",
    "title": "Ideas for Mapping Data",
    "section": "",
    "text": "There is a lot of data in the world, pick a set that you are comfortable with by the end of the first project day. You can go down a rabbit hole after the semester is over."
  },
  {
    "objectID": "data_for_mapping.html#caution",
    "href": "data_for_mapping.html#caution",
    "title": "Ideas for Mapping Data",
    "section": "",
    "text": "There is a lot of data in the world, pick a set that you are comfortable with by the end of the first project day. You can go down a rabbit hole after the semester is over."
  },
  {
    "objectID": "data_for_mapping.html#map-data-ideas-for-project-3",
    "href": "data_for_mapping.html#map-data-ideas-for-project-3",
    "title": "Ideas for Mapping Data",
    "section": "Map data ideas for project 3",
    "text": "Map data ideas for project 3\n\nEPA Toxic Release Inventory (TRI)\nhttps://www.epa.gov/toxics-release-inventory-tri-program/tri-basic-data-files-calendar-years-1987-present\n\n\nCDC Flu View Interactive.\nhttps://gis.cdc.gov/grasp/fluview/fluportaldashboard.html\n\n\nMassachusetts GIS Data\nhttps://www.mass.gov/info-details/massgis-data-layers\nOther states also have GIS Data\n\n\nSearch Geo Spatial Analysis on Kaggle\nhttps://www.kaggle.com/datasets?sort=usability&tags=13206-Geospatial+Analysis\n(Sort by usability)"
  },
  {
    "objectID": "course-materials/lectures/SQL-example-information-schema.html",
    "href": "course-materials/lectures/SQL-example-information-schema.html",
    "title": "dbplyr-SQL",
    "section": "",
    "text": "Setup\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.3     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.3     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(RMySQL)\n\nLoading required package: DBI\n\nlibrary(leaflet)\nlibrary(dbplyr)\n\n\nAttaching package: 'dbplyr'\n\nThe following objects are masked from 'package:dplyr':\n\n    ident, sql\n\ndb &lt;- dbConnect(\n  MySQL(),\n  host = \"scidb.smith.edu\",\n  user = \"sds192\",\n  password = \"DSismfc@S\"\n)\nknitr::opts_chunk$set(connection = db, max.print = 20)\n\n\n\nBig Idea\nData can live in a flat file (.csv) or relational database.\nIf the flat file is too big it’ll crash R (think of fec20).\nWe store large quantities in a database on a server and call up what we need.\nWe use the Structured Query Language (SQL) to do this.\n\n\nDifferent dialects of SQL\nWe’ll be using MySQL.\nThe server is in Bass Hall. It is a physical computer.\nNon efficient queries slow it down for everyone.\n\n\ndb?\n\nclass(db)\n\n[1] \"MySQLConnection\"\nattr(,\"package\")\n[1] \"RMySQL\"\n\n\n\n\nTake a look at the databases\n\n\nSHOW DATABASES;\n\n\n8 records\n\n\nDatabase\n\n\n\n\nairlines\n\n\ncitibike\n\n\nfec\n\n\nimdb\n\n\ninformation_schema\n\n\nlahman\n\n\nperformance_schema\n\n\nyelp\n\n\n\n\n\n\n\nChoose a database\n\nUSE citibike;\n\n\n\nLook at the tables\n\nSHOW TABLES;\n\n\n4 records\n\n\nTables_in_citibike\n\n\n\n\nstation_months\n\n\nstation_summary\n\n\ntrip_summary\n\n\ntrips\n\n\n\n\n\n\n\nDescribe a table\nThis shows what each variable (field) is and its type.\n\n\nDESCRIBE trips;\n\n\n9 records\n\n\nField\nType\nNull\nKey\nDefault\nExtra\n\n\n\n\nduration\nsmallint\nYES\n\nNA\n\n\n\nstart_time\ndatetime\nNO\nMUL\nNA\n\n\n\nstop_time\ndatetime\nNO\nMUL\nNA\n\n\n\nstart_station_id\nsmallint\nYES\nMUL\nNA\n\n\n\nend_station_id\nsmallint\nYES\nMUL\nNA\n\n\n\nbike_id\nsmallint\nYES\nMUL\nNA\n\n\n\nuser_type\ntext\nYES\n\nNA\n\n\n\nbirth_year\nsmallint\nYES\n\nNA\n\n\n\ngender\nsmallint\nYES\n\nNA\n\n\n\n\n\n\n\nDESCRIBE station_summary    ;           \n\n\n9 records\n\n\nField\nType\nNull\nKey\nDefault\nExtra\n\n\n\n\nstation_id\nsmallint\nNO\n\n0\n\n\n\nname\ntext\nYES\n\nNA\n\n\n\nlat\ndouble\nYES\n\nNA\n\n\n\nlon\ndouble\nYES\n\nNA\n\n\n\nnum_months\ndecimal(23,0)\nYES\n\nNA\n\n\n\nearliest\ndatetime\nYES\n\nNA\n\n\n\nlatest\ndatetime\nYES\n\nNA\n\n\n\nnum_starts\ndecimal(27,0)\nYES\n\nNA\n\n\n\nnum_stops\ndecimal(27,0)\nYES\n\nNA\n\n\n\n\n\n\n\n\nSQL to dplyr\n\n\n\nSQL\ndplyr\n\n\n\n\nSELECT\nselect(), mutate(), summarise()\n\n\nFROM\nthe data frame. data=\n\n\nWHERE\nfilter()\n\n\nGROUP BY\ngroup_by\n\n\nHAVING\nfilter() use after group_by()\n\n\nORDER BY\narrange()\n\n\nLIMIT\nhead()\n\n\n\n\n\nQuestion\nWhich station had the most bikes rented from it?\nProbably consider num_starts from station_summary.\n\n\nSELECT station_id, num_starts \n\nFROM station_summary \n\nLIMIT 10;\n\n\n10 records\n\n\nstation_id\nnum_starts\n\n\n\n\n72\n38308\n\n\n79\n26373\n\n\n82\n9588\n\n\n83\n14866\n\n\n116\n38377\n\n\n119\n3035\n\n\n120\n9173\n\n\n127\n58446\n\n\n128\n63044\n\n\n143\n22234\n\n\n\n\n\n\n\nORDER BY\n\n\nSELECT station_id, num_starts \n\nFROM station_summary \n\nORDER BY num_starts\n\nLIMIT 10;\n\n\n10 records\n\n\nstation_id\nnum_starts\n\n\n\n\n3278\n0\n\n\n3275\n0\n\n\n3276\n0\n\n\n3277\n0\n\n\n3213\n0\n\n\n3279\n0\n\n\n3202\n0\n\n\n3471\n0\n\n\n3273\n0\n\n\n3639\n0\n\n\n\n\n\n\n\nORDER BY DESC\n\n\nSELECT station_id, num_starts \n\nFROM station_summary \n\nORDER BY  num_starts DESC\n\nLIMIT 10;\n\n\n10 records\n\n\nstation_id\nnum_starts\n\n\n\n\n519\n162716\n\n\n497\n112218\n\n\n402\n108590\n\n\n435\n107133\n\n\n426\n105610\n\n\n3255\n97083\n\n\n490\n94872\n\n\n459\n90718\n\n\n514\n86833\n\n\n477\n85082\n\n\n\n\n\n\n\nWhere are the top 10 stations?\n\n\nSELECT station_id, num_starts, lat, lon \n\nFROM station_summary \n\nORDER BY  num_starts DESC\n\nLIMIT 10;\n\n\n10 records\n\n\nstation_id\nnum_starts\nlat\nlon\n\n\n\n\n519\n162716\n40.75187\n-73.97771\n\n\n497\n112218\n40.73705\n-73.99009\n\n\n402\n108590\n40.74034\n-73.98955\n\n\n435\n107133\n40.74174\n-73.99416\n\n\n426\n105610\n40.71755\n-74.01322\n\n\n3255\n97083\n40.75059\n-73.99468\n\n\n490\n94872\n40.75155\n-73.99393\n\n\n459\n90718\n40.74674\n-74.00776\n\n\n514\n86833\n40.76087\n-74.00278\n\n\n477\n85082\n40.75641\n-73.99003\n\n\n\n\n\n\n\nHow to bring an SQL query into R\n\ntop_10_data &lt;- dbGetQuery(conn = db, \n\n\"SELECT station_id, num_starts, lat, lon \n\nFROM station_summary \n\nORDER BY  num_starts DESC\n\nLIMIT 10;\")\n\nWarning in .local(conn, statement, ...): Decimal MySQL column 1 imported as\nnumeric\n\n\n\n\nPut points on map\n\nlibrary(leaflet)\n\nleaflet() |&gt;\n  addTiles()|&gt;\n  addMarkers(lat= ~lat, lng = ~lon, data=top_10_data)\n\n\n\n\n\n\n\nWrangling in SQL\nWhat is the average age of people leaving from each location?\n\n\nSELECT start_station_id, AVG(2023-birth_year) AS avg_age \n\nFROM trips \n\nWHERE 2023-birth_year &lt; 100\n\nGROUP BY start_station_id \n\nORDER BY start_station_id DESC\n\nLIMIT 10;\n\n\n10 records\n\n\nstart_station_id\navg_age\n\n\n\n\n3654\n43.8261\n\n\n3653\n40.1600\n\n\n3650\n36.2462\n\n\n3649\n44.4194\n\n\n3648\n41.1166\n\n\n3647\n43.8048\n\n\n3646\n38.8705\n\n\n3644\n46.5960\n\n\n3643\n44.7412\n\n\n3642\n42.5606\n\n\n\n\n\n\n\nJOIN\nThis query take a while, don’t execute it now.\n\n\nSELECT start_station_id, \n  AVG(2023-birth_year) AS age , \n  lat, \n  lon\n\nFROM trips \n\nJOIN station_summary ON trips.start_station_id = station_summary.station_id \n\nGROUP BY start_station_id\n\nORDER BY age DESC;\n\n\nDisplaying records 1 - 20\n\n\nstart_station_id\nage\nlat\nlon\n\n\n\n\n3237\n402.7122\n40.75383\n-73.94268\n\n\n298\n233.7158\n40.68683\n-73.97968\n\n\n225\n216.8843\n40.74195\n-74.00803\n\n\n3036\n189.7692\n40.79018\n-73.93029\n\n\n3282\n173.8735\n40.78307\n-73.95939\n\n\n3143\n172.2901\n40.77645\n-73.96418\n\n\n3160\n165.6663\n40.77897\n-73.97375\n\n\n2006\n159.9212\n40.76591\n-73.97634\n\n\n3040\n157.6471\n40.66402\n-74.00030\n\n\n2004\n154.1392\n40.72440\n-74.00470\n\n\n3374\n153.8073\n40.79948\n-73.95561\n\n\n3180\n147.0312\n40.69878\n-73.99712\n\n\n493\n144.9925\n40.75680\n-73.98291\n\n\n232\n143.2358\n40.69598\n-73.99015\n\n\n3114\n141.0478\n40.73165\n-73.96162\n\n\n3137\n137.6360\n40.77283\n-73.96685\n\n\n3136\n134.5695\n40.76637\n-73.97152\n\n\n217\n131.6999\n40.70277\n-73.99384\n\n\n224\n129.1457\n40.71146\n-74.00552\n\n\n3165\n128.8369\n40.77579\n-73.97621\n\n\n\n\n\n\n\nBring this into R\nUse the dbGetQuery() function. The first argument is the connection the second is the query as a character.\n\nage_by_station_data &lt;- dbGetQuery(conn = db, \n                          \"SELECT start_station_id, \n                          AVG(2023-birth_year) AS age , \n                          lat,\n                          lon\n                          \n                          FROM trips \n                          \n                          JOIN station_summary ON trips.start_station_id = station_summary.station_id \n                          \n                          GROUP BY start_station_id\n                          \n                          ORDER BY age DESC;\")\n\nWarning in .local(conn, statement, ...): Decimal MySQL column 1 imported as\nnumeric\n\n\n\n\nMake a map\n\nlibrary(leaflet)\n\nleaflet() |&gt;\n  addTiles()|&gt;\n  addMarkers(lat= ~lat, lng = ~lon, popup= ~as.character(age), data=age_by_station_data)\n\n\n\n\n\n\n\nTry some SQL with yelp\n\nSHOW the databases\nUSE yelp\nSHOW Tables\nDESCRIBE one of them\nMake a simple query\nFilter with WHERE or HAVING\n\n\n\nPart 2\n\n\nTwo magical verbs\nThese two functions will be helpful and are in the dbplyr library.\n\nshow_query()\ncollect()\n\n\n\nThis makes table connection with the server\n\n#This creates a tbl_sql object in R \n\n trips &lt;- db |&gt;\n   tbl(\"trips\")\n\n station_summary &lt;- db |&gt;\n   tbl(\"station_summary\")\n\nWarning in .local(conn, statement, ...): Decimal MySQL column 4 imported as\nnumeric\n\n\nWarning in .local(conn, statement, ...): Decimal MySQL column 7 imported as\nnumeric\n\n\nWarning in .local(conn, statement, ...): Decimal MySQL column 8 imported as\nnumeric\n\n\n\n\nWe can see the query\n\n# Do the average age wrangling again in R\n\n# The data still lives on the server\n\nstation_summary |&gt;\n\ninner_join( y= trips, by = c(\"station_id\"=\"start_station_id\")) |&gt;\n  \n  select(station_id, birth_year , lat, lon) |&gt;\n  \n  mutate(age= 2023-birth_year) |&gt;\n  \n  group_by(station_id)|&gt;\n  \n  summarise(average_age = mean(age, na.rm=TRUE)) |&gt;\n  \n  show_query()\n\n&lt;SQL&gt;\nSELECT `station_id`, AVG(`age`) AS `average_age`\nFROM (\n  SELECT *, 2023.0 - `birth_year` AS `age`\n  FROM (\n    SELECT `station_id`, `birth_year`, `lat`, `lon`\n    FROM `station_summary`\n    INNER JOIN `trips`\n      ON (`station_summary`.`station_id` = `trips`.`start_station_id`)\n  ) `q01`\n) `q02`\nGROUP BY `station_id`\n\n\n\n\nData on Server\nIf we run this, the data still live on the server\n\nstation_summary |&gt;\n\ninner_join( y= trips, by = c(\"station_id\"=\"start_station_id\")) |&gt;\n  \n  select(station_id, birth_year , lat, lon) |&gt;\n  \n  mutate(age= 2023-birth_year) |&gt;\n  \n  group_by(station_id)|&gt;\n  \n  summarise(lat,lon,average_age = mean(age, na.rm=TRUE)) \n\n\n\nUse collect() to bring data into R.\n\nage_by_station_R &lt;-\n  \n  station_summary |&gt;\n  \n  inner_join( y= trips, by = c(\"station_id\"=\"start_station_id\")) |&gt;\n  \n  select(station_id, birth_year , lat, lon) |&gt;\n  \n  mutate(age= 2023-birth_year) |&gt;\n  \n  group_by(station_id)|&gt;\n  \n  summarise(lat,lon,average_age = mean(age, na.rm=TRUE)) |&gt;\n  \n  collect()\n\nWarning in .local(conn, statement, ...): Decimal MySQL column 3 imported as\nnumeric\n\n\n\n\nMap"
  },
  {
    "objectID": "course-materials/lectures/day-30-leaflet.html",
    "href": "course-materials/lectures/day-30-leaflet.html",
    "title": "maps-leaflet",
    "section": "",
    "text": "Libraries\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.3     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(leaflet)\nlibrary(tidygeocoder)\nlibrary(maps)\n\n\nAttaching package: 'maps'\n\nThe following object is masked from 'package:purrr':\n\n    map\n\nlibrary(mapdata)\nlibrary(tmaptools)\nlibrary(sf)\n\nLinking to GEOS 3.11.0, GDAL 3.5.3, PROJ 9.1.0; sf_use_s2() is TRUE\n\n\n\n\n\nLeaflet\nHere is the leaflet vignette.\n\n\ngeocode some addresses\n\naddresses&lt;- tibble(address=c(\"Smith College\", \"2 Tyler Ct, Northampton, MA 01060\", \"Holyoke Community College\")) |&gt;\ngeocode(address, method=\"osm\") |&gt;\n  mutate(name = c(\"Smith College\",\"McConnell Hall\",\"Holyoke Community College\"))\n\nPassing 3 addresses to the Nominatim single address geocoder\n\n\nQuery completed in: 3 seconds\n\naddresses\n\n# A tibble: 3 × 4\n  address                             lat  long name                     \n  &lt;chr&gt;                             &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;                    \n1 Smith College                      42.3 -72.6 Smith College            \n2 2 Tyler Ct, Northampton, MA 01060  42.3 -72.6 McConnell Hall           \n3 Holyoke Community College          42.2 -72.7 Holyoke Community College\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLeaflet\nLeaflet is a package for interactive maps.\nLeaflet is tidy, the first argument a Leaflet funtion takes is a map object.\nNote: leftlet is not ggplot() add functions with the |&gt;.\n\n\nWorld Map\nThe addTiles() function just adds a map.\n\nleaflet() |&gt;\n  addTiles() \n\n\n\n\n\n\n\nPolygons\nThen leaflet needs to addPolygons() to show boundary lines.\n\n#Here I use the tidycensus package to get some boundary lines\n#| warnings: FALSE\n\n\nmass_pop_orig &lt;- \n  tidycensus::get_acs(\n    geography = \"county\", \n    variables = \"B01003_001\", \n    state = \"MA\",\n    geometry = TRUE\n  ) |&gt;\n  # Most of the maps we are duing use datum WGS84 so we need to tranform to that. See the datnum wikipedia page.\n  \n  st_transform('+proj=longlat +datum=WGS84')\n\nGetting data from the 2017-2021 5-year ACS\n\n\nWarning: • You have not set a Census API key. Users without a key are limited to 500\nqueries per day and may experience performance limitations.\nℹ For best results, get a Census API key at\nhttp://api.census.gov/data/key_signup.html and then supply the key to the\n`census_api_key()` function to use it throughout your tidycensus session.\nThis warning is displayed once per session.\n\n\nDownloading feature geometry from the Census website.  To cache shapefiles for use in future sessions, set `options(tigris_use_cache = TRUE)`.\n\n\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |                                                                      |   1%\n  |                                                                            \n  |=                                                                     |   1%\n  |                                                                            \n  |=                                                                     |   2%\n  |                                                                            \n  |==                                                                    |   2%\n  |                                                                            \n  |==                                                                    |   3%\n  |                                                                            \n  |===                                                                   |   4%\n  |                                                                            \n  |===                                                                   |   5%\n  |                                                                            \n  |====                                                                  |   5%\n  |                                                                            \n  |====                                                                  |   6%\n  |                                                                            \n  |=====                                                                 |   6%\n  |                                                                            \n  |=====                                                                 |   7%\n  |                                                                            \n  |=====                                                                 |   8%\n  |                                                                            \n  |======                                                                |   8%\n  |                                                                            \n  |======                                                                |   9%\n  |                                                                            \n  |=======                                                               |  10%\n  |                                                                            \n  |=======                                                               |  11%\n  |                                                                            \n  |========                                                              |  11%\n  |                                                                            \n  |========                                                              |  12%\n  |                                                                            \n  |=========                                                             |  12%\n  |                                                                            \n  |=========                                                             |  13%\n  |                                                                            \n  |=========                                                             |  14%\n  |                                                                            \n  |==========                                                            |  14%\n  |                                                                            \n  |==========                                                            |  15%\n  |                                                                            \n  |===========                                                           |  15%\n  |                                                                            \n  |===========                                                           |  16%\n  |                                                                            \n  |============                                                          |  17%\n  |                                                                            \n  |============                                                          |  18%\n  |                                                                            \n  |=============                                                         |  18%\n  |                                                                            \n  |=============                                                         |  19%\n  |                                                                            \n  |==============                                                        |  20%\n  |                                                                            \n  |===============                                                       |  21%\n  |                                                                            \n  |===============                                                       |  22%\n  |                                                                            \n  |================                                                      |  22%\n  |                                                                            \n  |================                                                      |  23%\n  |                                                                            \n  |=================                                                     |  24%\n  |                                                                            \n  |=================                                                     |  25%\n  |                                                                            \n  |==================                                                    |  25%\n  |                                                                            \n  |==================                                                    |  26%\n  |                                                                            \n  |===================                                                   |  27%\n  |                                                                            \n  |=======================                                               |  33%\n  |                                                                            \n  |================================                                      |  46%\n  |                                                                            \n  |=================================                                     |  47%\n  |                                                                            \n  |=================================                                     |  48%\n  |                                                                            \n  |==================================                                    |  48%\n  |                                                                            \n  |==================================                                    |  49%\n  |                                                                            \n  |===================================                                   |  49%\n  |                                                                            \n  |===================================                                   |  50%\n  |                                                                            \n  |===================================                                   |  51%\n  |                                                                            \n  |====================================                                  |  51%\n  |                                                                            \n  |====================================                                  |  52%\n  |                                                                            \n  |=====================================                                 |  52%\n  |                                                                            \n  |=====================================                                 |  53%\n  |                                                                            \n  |======================================                                |  54%\n  |                                                                            \n  |======================================                                |  55%\n  |                                                                            \n  |===========================================                           |  62%\n  |                                                                            \n  |=====================================================                 |  76%\n  |                                                                            \n  |======================================================                |  77%\n  |                                                                            \n  |======================================================                |  78%\n  |                                                                            \n  |=======================================================               |  78%\n  |                                                                            \n  |=======================================================               |  79%\n  |                                                                            \n  |========================================================              |  80%\n  |                                                                            \n  |=========================================================             |  81%\n  |                                                                            \n  |=========================================================             |  82%\n  |                                                                            \n  |==========================================================            |  82%\n  |                                                                            \n  |==========================================================            |  83%\n  |                                                                            \n  |==========================================================            |  84%\n  |                                                                            \n  |===========================================================           |  84%\n  |                                                                            \n  |===========================================================           |  85%\n  |                                                                            \n  |============================================================          |  85%\n  |                                                                            \n  |============================================================          |  86%\n  |                                                                            \n  |=============================================================         |  87%\n  |                                                                            \n  |=============================================================         |  88%\n  |                                                                            \n  |==============================================================        |  88%\n  |                                                                            \n  |==============================================================        |  89%\n  |                                                                            \n  |===============================================================       |  89%\n  |                                                                            \n  |===============================================================       |  90%\n  |                                                                            \n  |===============================================================       |  91%\n  |                                                                            \n  |================================================================      |  92%\n  |                                                                            \n  |=================================================================     |  93%\n  |                                                                            \n  |==================================================================    |  94%\n  |                                                                            \n  |==================================================================    |  95%\n  |                                                                            \n  |===================================================================   |  95%\n  |                                                                            \n  |===================================================================   |  96%\n  |                                                                            \n  |====================================================================  |  97%\n  |                                                                            \n  |====================================================================  |  98%\n  |                                                                            \n  |===================================================================== |  98%\n  |                                                                            \n  |===================================================================== |  99%\n  |                                                                            \n  |======================================================================| 100%\n\n\n\n\nPolygons\n\nleaflet(mass_pop_orig) |&gt;\n  addTiles() |&gt;\n  addPolygons()\n\n\n\n\n\n\n\nLittle markers\nLeftlet can add markers they’re more dynamic geom_point.\nGive the marker a pop up name\n\nleaflet() |&gt;\n  addTiles() |&gt;\n  addPolygons(data = mass_pop_orig) |&gt;\n  addMarkers(data = addresses, lng=~long, lat=~lat, popup = ~name)\n\n\n\n\n\n\n\nAdding Circle Markers\n\nma_cities &lt;- us.cities |&gt;\n  filter(country.etc =='MA')\n\nleaflet() |&gt;\n  addTiles() |&gt;\n  addPolygons(data = mass_pop_orig) |&gt;\n  addMarkers(data = addresses, lng=~long, lat=~lat, popup = ~name, ) |&gt;\n  addCircleMarkers(data = ma_cities, lng=~long, lat=~lat, popup = ~name, color='black',clusterOptions = markerClusterOptions() ) \n\n\n\n\n\n\n\n\nYou can also change your map type.\nHere is your list of tiles\n\n\nYou can also change your map type.\n\n\n\n\n\n\n\n```\n\n\nMore Tiles\n\nMost of these work:\nNasa: NASAGIBS.ViirsEarthAtNight2012\nGoogle map: Esri.WorldImagery\nGray: Esri.WorldGrayCanvas\nTerrain: Esri.WorldTerrain\nTopo Map: Esri.WorldTopoMap"
  },
  {
    "objectID": "course-materials/lectures/Day_26_across_maps.html",
    "href": "course-materials/lectures/Day_26_across_maps.html",
    "title": "iteration",
    "section": "",
    "text": "These functions allow us to preform the same operation across multiple rows.\nmap() comes from the purr package.\nacross() comes from the dplyr package."
  },
  {
    "objectID": "course-materials/first-day-survey/Data-Viz-No-Computers.html#names-and-surveys",
    "href": "course-materials/first-day-survey/Data-Viz-No-Computers.html#names-and-surveys",
    "title": "No Computers Data Viz",
    "section": "Names and Surveys",
    "text": "Names and Surveys\nSurvey Questions"
  },
  {
    "objectID": "course-materials/first-day-survey/Data-Viz-No-Computers.html#data-viz-no-computers",
    "href": "course-materials/first-day-survey/Data-Viz-No-Computers.html#data-viz-no-computers",
    "title": "No Computers Data Viz",
    "section": "Data Viz no computers",
    "text": "Data Viz no computers\nSheets data\n\nData Frame\nObservations\nTidy Data\nVariables\nVariable Types"
  },
  {
    "objectID": "course-materials/first-day-survey/Data-Viz-No-Computers.html#take-1-hand-drawn-graphs-of-survey-questions.",
    "href": "course-materials/first-day-survey/Data-Viz-No-Computers.html#take-1-hand-drawn-graphs-of-survey-questions.",
    "title": "No Computers Data Viz",
    "section": "Take 1: Hand drawn graphs of survey questions.",
    "text": "Take 1: Hand drawn graphs of survey questions.\nDraw a graph of a variable. Do not write your name.\n\nIt does not need to be perfect.\nTry to make it correct.\n\nIt is fine if its not correct."
  },
  {
    "objectID": "course-materials/first-day-survey/Data-Viz-No-Computers.html#talk-to-someone-close-to-you.",
    "href": "course-materials/first-day-survey/Data-Viz-No-Computers.html#talk-to-someone-close-to-you.",
    "title": "No Computers Data Viz",
    "section": "Talk to someone close to you.",
    "text": "Talk to someone close to you.\nAnswer these questions:\n\nIs the graph’s message or story clear?\nWhat is missing from each graph?\nWhat is distracting from the graph?\nWhat does the graph do well?"
  },
  {
    "objectID": "course-materials/first-day-survey/Data-Viz-No-Computers.html#what-makes-a-clear-graph",
    "href": "course-materials/first-day-survey/Data-Viz-No-Computers.html#what-makes-a-clear-graph",
    "title": "No Computers Data Viz",
    "section": "What makes a clear graph?",
    "text": "What makes a clear graph?\nClass discussion."
  },
  {
    "objectID": "course-materials/first-day-survey/Data-Viz-No-Computers.html#baumers-thoughts",
    "href": "course-materials/first-day-survey/Data-Viz-No-Computers.html#baumers-thoughts",
    "title": "No Computers Data Viz",
    "section": "Baumer’s Thoughts",
    "text": "Baumer’s Thoughts\nSome of the following slides were borrowed by the text’s author."
  },
  {
    "objectID": "course-materials/first-day-survey/Data-Viz-No-Computers.html#a-misleading-chart-from-apple",
    "href": "course-materials/first-day-survey/Data-Viz-No-Computers.html#a-misleading-chart-from-apple",
    "title": "No Computers Data Viz",
    "section": "A misleading chart from Apple",
    "text": "A misleading chart from Apple"
  },
  {
    "objectID": "course-materials/first-day-survey/Data-Viz-No-Computers.html#pie-charts",
    "href": "course-materials/first-day-survey/Data-Viz-No-Computers.html#pie-charts",
    "title": "No Computers Data Viz",
    "section": "Pie charts",
    "text": "Pie charts\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAre 6-cylinder engines more common among manuals or automatics?"
  },
  {
    "objectID": "course-materials/first-day-survey/Data-Viz-No-Computers.html#unclear-scales",
    "href": "course-materials/first-day-survey/Data-Viz-No-Computers.html#unclear-scales",
    "title": "No Computers Data Viz",
    "section": "Unclear Scales",
    "text": "Unclear Scales\n\n\nOften not very clearly defined\nEasy to lie by manipulating scales\nWhy perspective?\nWidth of lines?"
  },
  {
    "objectID": "course-materials/first-day-survey/Data-Viz-No-Computers.html#clearer-scales",
    "href": "course-materials/first-day-survey/Data-Viz-No-Computers.html#clearer-scales",
    "title": "No Computers Data Viz",
    "section": "Clearer Scales",
    "text": "Clearer Scales\n\n\nGood graphics have clear scales\n\nRemember iPhone sales graphic"
  },
  {
    "objectID": "course-materials/first-day-survey/Data-Viz-No-Computers.html#section",
    "href": "course-materials/first-day-survey/Data-Viz-No-Computers.html#section",
    "title": "No Computers Data Viz",
    "section": "",
    "text": "1\n\n\n\n\n\nhttps://en.wikipedia.org/wiki/Misleading_graph#Improper_scaling"
  },
  {
    "objectID": "course-materials/first-day-survey/Data-Viz-No-Computers.html#section-1",
    "href": "course-materials/first-day-survey/Data-Viz-No-Computers.html#section-1",
    "title": "No Computers Data Viz",
    "section": "",
    "text": "1\nhttps://en.wikipedia.org/wiki/Misleading_graph#3D"
  },
  {
    "objectID": "course-materials/first-day-survey/Data-Viz-No-Computers.html#section-2",
    "href": "course-materials/first-day-survey/Data-Viz-No-Computers.html#section-2",
    "title": "No Computers Data Viz",
    "section": "",
    "text": "1\nhttps://en.wikipedia.org/wiki/Chartjunk"
  },
  {
    "objectID": "course-materials/first-day-survey/Data-Viz-No-Computers.html#balance-of-art-vs.-science",
    "href": "course-materials/first-day-survey/Data-Viz-No-Computers.html#balance-of-art-vs.-science",
    "title": "No Computers Data Viz",
    "section": "Balance of art vs. science",
    "text": "Balance of art vs. science\n\n\nData graphics:\n\npurpose is to convey meaning\nscientific, rigorous\npeer-reviewed\nclear\ncreative!\n\n\nInfographics:\n\npurpose might be to draw eyeballs\nentertaining?\nsales or marketing?\npublic sphere\ncreative\n\n\n\nWe’re only interested in the former"
  },
  {
    "objectID": "course-materials/first-day-survey/Data-Viz-No-Computers.html#other-people-have-thought-about-this",
    "href": "course-materials/first-day-survey/Data-Viz-No-Computers.html#other-people-have-thought-about-this",
    "title": "No Computers Data Viz",
    "section": "Other people have thought about this",
    "text": "Other people have thought about this\nDo’s and Don’t\nTufte’s Data to Ink Ratio\nFlowing Data"
  },
  {
    "objectID": "course-materials/first-day-survey/Data-Viz-No-Computers.html#some-graphs-to-discuss-in-groups",
    "href": "course-materials/first-day-survey/Data-Viz-No-Computers.html#some-graphs-to-discuss-in-groups",
    "title": "No Computers Data Viz",
    "section": "Some Graphs to discuss in groups",
    "text": "Some Graphs to discuss in groups\nThe Economist’s Graph detail\nGraphs from the NYTimes"
  },
  {
    "objectID": "course-materials/syllabus/syllabus.html",
    "href": "course-materials/syllabus/syllabus.html",
    "title": "Basic information",
    "section": "",
    "text": "Course title: SDS 192: Introduction to Data Science\nContact Info:\n nschwab@smith.edu\n 413-585-3440\n Nics-Github\nOffice location: McConnell 213\nEmail: nschwab@smith.edu\nMeeting locations/times:\n\nMorning Section\n-   MWF: 10:50 AM - 12:05 PM / Sabin-Reed 220\n\n\nGetting help:\n\nFor non personal/sensitive questions, ask on the #questions channel on Slack. For personal/sensitive matters, Slack DM Professor Schwab.\nStudent hours\nSpinelli Center\n\n\n\n\n\nI will respond to Slack messages sent during the week within 24h. I will respond to Slack messages sent during the weekend at my own discretion.\nIf possible, please only Slack me with briefer and administrative questions; I prefer having more substantive conversations in person as it takes me less energy to understand where you are at.\nI will do my best to return all grading as promptly as possible."
  },
  {
    "objectID": "course-materials/syllabus/syllabus.html#work-life-balance",
    "href": "course-materials/syllabus/syllabus.html#work-life-balance",
    "title": "Basic information",
    "section": "",
    "text": "I will respond to Slack messages sent during the week within 24h. I will respond to Slack messages sent during the weekend at my own discretion.\nIf possible, please only Slack me with briefer and administrative questions; I prefer having more substantive conversations in person as it takes me less energy to understand where you are at.\nI will do my best to return all grading as promptly as possible."
  },
  {
    "objectID": "course-materials/syllabus/syllabus.html#projects-30",
    "href": "course-materials/syllabus/syllabus.html#projects-30",
    "title": "Basic information",
    "section": "Projects 30%",
    "text": "Projects 30%\nThere are four projects to complete during the semester. They will be completed collaboratively with a team of students using SCRUM."
  },
  {
    "objectID": "course-materials/syllabus/syllabus.html#final-project-20",
    "href": "course-materials/syllabus/syllabus.html#final-project-20",
    "title": "Basic information",
    "section": "Final project 20%",
    "text": "Final project 20%\nThere will be a final project due the last day of classes. These will be completed in groups during the last few weeks of class."
  },
  {
    "objectID": "course-materials/syllabus/syllabus.html#quizzes-20",
    "href": "course-materials/syllabus/syllabus.html#quizzes-20",
    "title": "Basic information",
    "section": "Quizzes 20%",
    "text": "Quizzes 20%\nThere are 3 or 4 self schedules quizzes this semester."
  },
  {
    "objectID": "course-materials/syllabus/syllabus.html#labs-20",
    "href": "course-materials/syllabus/syllabus.html#labs-20",
    "title": "Basic information",
    "section": "Labs 20%",
    "text": "Labs 20%\nMany Fridays there will be in class labs. You will have until the following Wednesday to complete the lab. Its important to complete and stay on top of the problem sets. They will be graded on the following scale:\n\n5 points: Assignment is complete, mostly correct, rendered and submitted\n4 points: Assignment is nearly complete, mostly correct, rendered and submitted\n3 points: Assignment is around 50% of the problems have been completed, are correct, the assignment is rendered\n2 points: Assignment is at most 50% complete, the problems are incorrect and is not correctly rendered\n1 point : Assignment is largely unfinished and is not rendered\n0 points: No assignment is turned in."
  },
  {
    "objectID": "course-materials/syllabus/syllabus.html#engagement",
    "href": "course-materials/syllabus/syllabus.html#engagement",
    "title": "Basic information",
    "section": "Engagement 10%",
    "text": "Engagement 10%\nIt is difficult to explicit codify what constitutes “an engaged student,” so instead I present the following rough principle I will follow: you’ll only get out of this class as much as you put in. That being said, here are multiple pathways for you to stay engaged in this class:\n\nParticipation in all SCRUM Sprints\nAsking and answering questions in class.\nWorking and staying focused in class.\nComing to office hours.\nPosting questions on Slack.\nEven better: Responding to questions on Slack.\nComplete Classwork problems"
  },
  {
    "objectID": "course-materials/syllabus/syllabus.html#tentative-assignment-schedule",
    "href": "course-materials/syllabus/syllabus.html#tentative-assignment-schedule",
    "title": "Basic information",
    "section": "Tentative Assignment schedule",
    "text": "Tentative Assignment schedule\nLabs will be assigned regularly and due by midnight the following Monday.\nProject 1- due after reading chapter 4 of MDSR\nProject 2- due after reading chapter 5 of MDSR\nProject 3- due after reading chapter 17 of MDSR\nFinal Project/ Presentation during our final time.\nFor a more up to date schedule see the course’s website."
  },
  {
    "objectID": "course-materials/syllabus/syllabus.html#policies-1",
    "href": "course-materials/syllabus/syllabus.html#policies-1",
    "title": "Basic information",
    "section": "Policies",
    "text": "Policies\n\nAccommodation\nSmith is committed to providing support services and reasonable accommodations to all students with disabilities. To request an accommodation, please register with the Disability Services Office at the beginning of the semester. To do so, call (413) 585-2071 to arrange an appointment with Laura Rauscher, Director of Disability Services."
  },
  {
    "objectID": "course-materials/syllabus/syllabus.html#policies-2",
    "href": "course-materials/syllabus/syllabus.html#policies-2",
    "title": "Basic information",
    "section": "Policies",
    "text": "Policies\n\nInclusion\n\n\n\n\n\n\nInclusion policy\n\n\n\nWe are committed to fostering a classroom environment where all students thrive. We are committed to affirming the identities, realities and voices of all students, especially those from historically marginalized or underrepresented backgrounds. We are dedicated to creating a space where everyone in the class is respected, is free from discrimination based on race, ethnicity, sexual orientation, religion, gender identity, disability status, and other identities, and feel welcome and ready to learn at your highest potential.\nIf you have any concerns or suggestions for how to make this class more inclusive, please reach out to your instructor.\nWe are here to support your learning and growth as data scientists and people!\n\n\n\n\nAttendance\nWe expect you attend class in person. If you choose to come to class, we expect your full attention. Please put your phone away during class unless otherwise directed.\nIn keeping with Smith’s core identity and mission as an in-person, residential college, SDS affirms College policy (as per the Provost and Dean of the College) that students will attend class in person. SDS courses will not provide options for remote attendance. Students who have been determined to require a remote attendance accommodation by the Office of Disability Services will be the only exceptions to this policy. As with any other kind of ADA accommodations, please notify your instructor during the first week of classes to discuss how we can meet your accommodations.\nIf you are unable to attend class for any reason, please follow the materials on the course website and check with another student about what happened in class.\n\n\nCollaboration\n\n\n\n\n\n\nWarning\n\n\n\nMuch of this course will operate on a collaborative basis, and you are expected and encouraged to work together with a partner or in small groups to study, complete labs, and prepare for exams. However, all work that you submit for credit must be your own. Copying and pasting sentences, paragraphs, or blocks of code from another student or from online sources is not acceptable and will receive no credit. No interaction with anyone but the instructors is allowed on any exams or quizzes.\n\n\n\n\nAcademic Honor Code Statement\nAll students, staff and faculty are bound by the Smith College Honor Code, which Smith has had since 1944.\n\nSmith College expects all students to be honest and committed to the principles of academic and intellectual integrity in their preparation and submission of course work and examinations. Students and faculty at Smith are part of an academic community defined by its commitment to scholarship, which depends on scrupulous and attentive acknowledgement of all sources of information, and honest and respectful use of college resources.\n\nCases of dishonesty, plagiarism, etc., will be reported to the Academic Honor Board.\n\n\nCode of Conduct\nAs the instructor and assistants for this course, we are committed to making participation in this course a harassment-free experience for everyone, regardless of level of experience, gender, gender identity and expression, sexual orientation, disability, personal appearance, body size, race, ethnicity, age, or religion. Examples of unacceptable behavior by participants in this course include the use of sexual language or imagery, derogatory comments or personal attacks, deliberate misgendering or use of “dead” names, trolling, public or private harassment, insults, or other unprofessional conduct.\nAs the instructor and assistants we have the right and responsibility to point out and stop behavior that is not aligned to this Code of Conduct. Participants who do not follow the Code of Conduct may be reprimanded for such behavior. Instances of abusive, harassing, or otherwise unacceptable behavior may be reported by contacting the instructor.\n\n\n\n\n\n\nImportant\n\n\n\nAll students, the instructor, the lab instructor, and all assistants are expected to adhere to this Code of Conduct in all settings for this course: lectures, labs, office hours, tutoring hours, and over Slack.\n\n\nThis Code of Conduct is adapted from the Contributor Covenant, version 1.0.0, available here."
  },
  {
    "objectID": "course-materials/syllabus/syllabus.html#resources",
    "href": "course-materials/syllabus/syllabus.html#resources",
    "title": "Basic information",
    "section": "Resources",
    "text": "Resources\n\nMoodle and course website\nThe course website and Moodle will be updated regularly with lecture handouts, project information, assignments, and other course resources. Grades will be recorded on Moodle. Please check both regularly.\n\n\nCommunication\n\n Slack is the primary mechanism for course-related discussions of all kinds. Please do not email the course instructor with course-related questions! Instead, post these on #questions on Slack. If discretion is absolutely necessary, private message the instructor on Slack.\n\n\n\nWriting\nYour ability to communicate results (which may be technical in nature) to your audience (which is likely to be non-technical) is critical to your success as a data analyst. The assignments in this class will place an emphasis on the clarity of your writing.\n\n\nWriting Enriched Curriculum\nThis course is part of Smith College’s Writing Enriched Curriculum. As such, the course supports the Writing Plan of the Program in Statistical & Data Sciences.\nPlease read the SDS Writing Plan for more information.\n\n\nThe Spinelli Center\nThe Spinelli Center (now in Seelye 207) supports students doing quantitative work across the curriculum. In particular, they employ:\n\nSDS Tutors available from 7:00–9:00pm on Sunday–Thursday evenings in Burton 301. These students are trained to help you with your statistics and R questions.\nA Data Research and Statistics Counselor (Osman Keshawarz) who keeps both drop-in hours and appointments. Students are welcome to email qlctutor@smith.edu to make an appointment.\n\nYour fellow students are also an excellent source for explanations, tips, etc."
  }
]